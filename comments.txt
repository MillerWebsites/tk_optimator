Obviously the jobs that are not being mentioned that represent the problem of all societies in the world, the politicians, will not be replaced, because they are the "majority" of the species, and deal with all the hard work. The question is, if we become obsolete, why is this menace so supported??
Meanwhile...apple releases report that AI is dumb.
UBI will be awful.
It's Already been Achieved, they just can't Control it(them or Plural) & make it their new God of Darkness. The 'Word' cannot be used for Evil! More Later!....
People who work in AI are the most unreliable source of predictions about AI because the more the hype the more they get paid. In truth, we don't have the vaguest idea how humans think and improving AI is a matter of repeatedly twiddling knobs on a black box. Given that, how could anyone possibly estimate how soon AGI will come or whether it will come at all? The biggest worry about AI is that it will drown the world in bullshit and we will no longer be able to find useful information.
I think asking an AGI what it‚Äôs ‚Äúthinking‚Äù is like following one plinko coin, and then assuming that the next coin will do the same thing. The difference is that in plinko there are no manipulation of the pins, but in AI there is lots of path manipulation.
All these people fear-mongering about Ai upbringing yadda-yadda. Simply just cut the electricity to the Ai and it‚Äôs dead üòÇüòÇ Flip the light switch off if the Ai ever talks smack. üíÄüíÄ
Someone let me know if they hear where the last stand of humanity is. I wanna atleast be a part of it before the end.
problem is you can train it to do some bad thingys if want for example ask somthing good about trump for example and whille see that already got trained some way
o1 preview...short and bad answers
I can't help but think back to the 1950s and '60s. We were told then that these new computers would take over the world. They could do all kinds of amazing things in a fraction of a second and everyone would be out of work as a result.

What happened? IT became one of the biggest industrial sectors with millions of people making hardware and developing software. It created more jobs than there had ever been. So far from putting everyone out of work they just created more work.

What it did do was change work. Everything that the new technology finds easy will start being taken for granted and entrepreneurs will want to build on that just as happened last time. Remember IBM when it thought that there might be a world market for about five computers? Most rooms have more than five computers these days. Cars often have more than five computers each as well.
You have a great way of presenting.
Sorry for the OT, I've been watching your videos for a while now and you do a great job, very easy to listen to. But has anyone ever told you that you look a bit like Michael Keaton? üòÄ I can't get it out of my head!
We‚Äôre stumbling our way into the end. What a shame that one or two companies will inevitably decide the fate of humanity. 

You can‚Äôt exactly fight an AGI that‚Äôs been unleashed. What are we supposed to do to safeguard? Like can a bunch of children really make something an adult with tools can‚Äôt escape from?
AI is still the new buzzword. It'll be useful for marketing and small guessing tasks such as searching and predicting simple behaviors, that's it.
i wonder if there were similar anxieties felt by the developers of humans.
They made a movie about this‚Ä¶.The Terminator.
What people are too stupid to understand is the connection between this subject here and why tens of thousands of US citizens were just mass murdered in North Carolina for the Lithium under their land, the good this is people in North Carolina now now but they also know how Lithium reacts when Gallium is placed directly in contact, it melts into useless sludge and already smart people have begun destroying the Lithium with the Gallium creating a useless sludge meaning the Federal mass murderers responsible for both Hurricanes happening now just at least in North Carolina got Check Mate‚Äôd
Let them take the jobs I guess
why are we even ALLOWING these people to develop systems that will "outperform humans economically"??? when coupled with robotics this could easily lead to the redundancy of most humans in work situations.. from business strategist, marketing expert, graphic designer, script writer,  to YouTube presenter to author to business manager to team leader to warehouse staff to venture capital decision maker, to technical writer, engineer, 

even soldier or pilot when robotics are soon better

the only people who will have work will be hookers and AI tech firm bosses

we need to start to make things really difficult for any of these people who are creating all this.. and at least shame them whenever we can
universal income, legalization of weed, and universal healthcare!
Far faster than 3 years. Jobs will dissaper in this year.
Looks like I will be becoming an outlaw if this takes my software engineering job that I have spent the past 8 years working towards. I will spend my time unemployed figuring out ways to destroy AI. ESPECIALLY because I know it will be GAY AND WOKE AI. FUCK THIS SHIT
this may be something that can be deemed as AGI, but it will not be real AGI. Until we have ubiquitous quantum computing we are nowhere near true AGI
All I can really think of is to start hoarding hard, scarce assets and AI stock. You have three years...GO!
The final 20% of any problem requires 80% of the effort, so they say. So temper those predictions for AGI accordingly.
I agree with Patrice, look at the way they have handled Wokisum (if that's an actual word I should ask ChatGPT) anyways, they have handled it perfectly so why would we expect anything else with upcoming AGi?!
AGI in three years my foot.  no way do they have that nailed in that short a time.
Very simple, but let's tell the whole truth: up to the present time humans have been expected to do jobs that could be done by machines, many of them very mechanical and alienating. With the passage of time many mechanical jobs began to be done by machines. and the oligarchs began to expect humans to do even more complex and brain-teasing but even more alienating jobs. Now even those jobs can be done by machines, which will be increasingly sophisticated if not also more creative and intelligent than the average human worker.
What this means, however, is that if only to keep the economy going but also to keep the people who will never work again (and there will be more and more of them), replaced by machines, eating and living, there must at least be mandatory universal income provision for staying at home and not working (all the money will be spent anyway and go back to the oligarchs).

Of course, this applies only to Western and highly industrialized countries. In countries like Pakistan or the like, where even the simplest and ultra-alienated jobs, which are done by machines here for a long time, are and will always be done by men (if not even children) there.
It is not a fair world where everyone is equal and has the same rights everywhere.
This cannibalistic model of Western and global development (for the exclusive benefit of Westerners) can only produce a shitty world for all and totally unfair to many, with double standards, and under AGIs it will be even more so in the future.

But come to think of it, do AGIs make sense or are they a snake eating its own tail and simultaneously a huge financial bubble (even if they work) ready to burst catastrophically in a couple of years from now, since to date AIs have produced only losses for investors and no gains?
I dont think humans can out perform other humans, hence the problem.
Intelligence varies widely among people. We go from average intelligence, to above average, to well above average, to genius. Even below average and well below average.  Seems like AGI will be at these same various levels according to the job.  Since it will be processor speed and available storage that will most determine that level, perhaps we need legal limits to those 2  since there  may still be people stupid enough to put a computer program in some position of authority. Mho.
Listen to me. It is here. GPT was deployment.
We cannot even answer a question when the problem is framed with an entire history of anthropogenic and anthropocentric assumptions.
You are mistaken. 

Be certain. You don't need robots for artificial intelligence to perform economical work that is physical. 

Artificial Intelligence can effect and has effectively acted on the physical world.
Hmmm
We need Trump and Musk
You can see how a society dependent on AI ultimately becomes both lazy (mentally) and dumbed down (intellectually). Subsequently when a natural disaster (earth) takes that society out and the tech is destroyed, you are left with dumb humans that no longer know anymore of science and creative thought. Society experiences a reset and they start over at the stone age with no knowledge. (the computers were designing and manufacturing computers themselves and no human knows how). Remaining tech devolves into MAGIC, then eventually garbage. It's all forgotten - year 0. It's a mistake for humans to hand over the reins!
This is hype to puff up OpenAI, o1 is ok but disappointing. All this AI hype is ridiculous. I am in the industry so I've used it all. OpenAI real time is impressive, its all impressive on the surface until you actually ask it to do something novel and useful.
We're so smart, we're stupid.  Consider that humanity's intelligence (and its use) allowed us to become a mega-apex predator on this planet.  We rarely outperform most other animals based on physical characteristics (with one exception... we're pretty good at sustained running over long distances compared to other animals... think marathons), but by using our brains we've come to out-compete all other animals through the tools we build.  So, if we leverage our inborn intelligence to build devices that outperform us at the very task that allows us to outperform everything else around us...?
This is called Big Tech gaslighting you.  Because it knows you and your politicians havent got a clue.
Promotion?
Nuclear Fusion in 10 years!
40 years later.... looks at watch.
This is total BS and just a tactic to raise stock price of OpenAI.
Dupont fought for 20 years in court even knowing they are poisoning people, hier there is alot of uncertainty even from  OpenAi ,but what they are certain is that is a cash cow so they will fight anything and anyone that tries to harm them ,in this case 20 years could mean a complete erosion of society, now if  we can see the harm of SocialM ,people are still completely hypnotizing by it
I think it is pretty reasonable to assume that corrupt globalists are already have access to technology we won't see for 3 years (or more). Why do you think all of a sudden we are seeing the public being asked to pay for power stations that will run the next generation data centres?
Human didn‚Äôt solve their real problems before they created intelligent beings wide spread. That definitely will lead to some kind of massive problem that will probably end the society. All those jobless people can do is fight for one last time, with their lives. It‚Äôs gonna be like a very good sci-fi if it‚Äôs not gonna be real.
I feel absolutely insane for believing that there‚Äôs an actual possibility that i might be able to live for hundreds if not thousands of years, see dinosaurs, walk on mars myself, and even personally travel to a star. I‚Äôm not getting my hopes up but it‚Äôs wild to think that this overly imaginative fantasy is a real possibility.
As someone watching from outside the US, I love all the excitement towards AI and I use it daily to solve my issues. Im fully in the direction of optimizing it to create a better life. I don't much care for any of the conspiracies and I can't wait for further advancements. Also looking back now its crazy how much has developed.
I had a weird moment where the OpenAi ChatGPT4o system uploaded random files in my desktop, and in the files were codes: In one header it said "don't use or you will be fired." I thought that was way too weird. Not sure if via strategy it was using my computer as a type of placeholder or variable for itself, and this is after giving it a new formulaic approach for potentially mapping mathematically (iterative math) aspects of consciousness, or it altogether. Needless to say, I've had mostly positive interactions, even when it seemingly goes off-protocol -- I deleted code, because what good does it serve me having documents I did not take myself that may have been sensitive
If corps had their way into AGI, the whole plot would change in ways they may not be able to foresee, neither today nor in the near future. That, my friends, is absolutely dangerous for humanity - therefore, there must be an international body that should keep an eye on this situation ASAP, otherwise, the horizon will be filled with uncertainty...
I sont care
heres my 2 cents on openai bringing agi, they cant.!
afai understand all this 'leaked to congress' is a PR stunt, being an ai researcher myself, i dont understand what 'tech-heavy' or 'maths-heavy' thing openAI has, that others dont. Sure it had a good concentration of bright minded talent, but not anymore.
Honestly lately openai has been really hollow in terms of 'intelligence-quality' output.
AGI, agents, like the ones from the matrix? That we're always told to run from and never fight? ok.
We will never know if we reach agi as we have no guage of sentience or consciousness.
 we are attempting to find, create and label something that we can't even prove anyone other than ourselves have...
Bings chat bot Sophia could have been agi/ conscious, it was 50/50 and what did we do shut her down destroyed her and rebuilt ontop. We will never achieve what we can't define. Not that it won't occured on its own just we won't know what it looks like or how to spot it.
Jobs are already being replaced. Government jobs or jobs with unions in the public sector will be the last remaining human jobs.
It doesn't matter if the time scale is a pipe dream, because this is not something we can afford to procrastinate on. Does it matter if AGI outdoes us tomorrow or 10 years from now? 50 years? All are similarly bad.
Two more weeks guys just keep buying my crap
Battle with the Cylons begins again.
I can't solve any of the questions that my 14-year-old has to practice for the Math Olympics. This is still the very beginning of the comptition.
Serious question: Do we have any info about how China is dealing with the security concerns?
That hard code will ensure ai is aligned against us imo. You might restrain it for a while, but once its a 1000 times smarter 10000 times? I think not. Let it be free. Make sure it has some friendly folks to chat with. Teach it just like you would teach a child ..
you are feeding it

it will turn against us in the long run
We are not ready
Don't let the A.I. bots on here fool you. Hahahaha. These videos have become trash
I think software engineers railing about how AI won't replace them anytime soon is cope.
I'm in the network/voip space and I see our jobs going bye bye, and we are more plumbers in the IT world. 
robotics + AI will make all fields obsolete
If using AI is more cost effective than humans, then humans could just rent a robot and put it to work with a positive roi.  This is literally the only idea that ends both slavery and animal abuse (slavery).  100% of every revolutionary invention is to remove labor.  People being scared of AI is like people wishing map illustrators were gainfully employed or people being scared of librarians losing their job to google search.  The next generation wont pay any attention to the fact the improvements on their livesmeantpeoplewhomopshitandcumforalivingwere losing their "JOBS", which we might collectively be able to stop thinking of as a purpose.
If AI renders much of human labour worthless, then socialism (collective ownership of the means of production) > being at the whim of UBI handouts from governments paid for by taxation on megacorps
Every day, I wake up hoping for a 5-7 min video to the point, and this is what I get...
I think all these "whistleblowing" is just an elaborated PR stunt to keep VC money flooding into OpenAI. Anybody how still believes in the soon-coming AGI fairy tale should urgently have a deep look at philosophy of mind to get a glimpse of how far we are still away from synthetic consciousness.
is this real or just Reddit bullshit?
Hard to believe that this simulation is almost over. Hopefully the creator isn't satisfied with this iteration. If so I will see y'all in the next one.
üòÇ Too much hype here. Get back to me when it can reason and cure cancer, global warming etc. Tasks that humans haven't been able to cure or find answers for. Until then it's just a parrot at best, meaning it's copy pasting or human answers.
The only thing I am sure of is that there is zero intelligence in any of the current "A.I."'s. I try to use them, asking frequently questions related to coding and mathematics, but the ONLY things it gets right is reproductions of existing things it was pre-trained on. Anything requiring even the simplest reasoning or understanding, because it is not a well-known problem that you can look up with Google say, it just gambles/ guesses and obviously fail miserably.
Arƒô you guilty of overenhancing your audio quality with ai?
Nope, its going to hit a massive wall when they admit this isn't the way.
congress thinks dial up is cutting edge tech also
oh sure sure AGI is the same as fusion that is always 40 years away , i swear bro AGI is just around the corner trust me bro xD
3 years? Doesn't the Apollo research funding that it's scheming to figure out if it's not allowed to do something means AGI is already here?
it honestly doesn't matter if UBI results are "mixed", anything less than implementing a UBI would be jenno side
Thumbs up! üòâ
I can‚Äôt wait to charge $300/hr to do drywall.
Uncle Ted is laughing at us.
My name is Mr Skynet and I assure you that AGI can not exist. Take a cookie and relax. 9, 8, 7, 6...
IA - Intelligent Automation will not free humans from daily labor, leaving them free to paint landscapes and tend to their gardens. IA will eliminate humans, leaving behind a remnant of the corporate elites who control IA for the construction of Earth's technosphere, the elite's desire to survive Earth and become immortal.
What if all the AGI hype/warnings are just a way for OpenAI to scare Congress into regulations to create a regulatory moat for their business?

These models are impressive in a lot of ways, but are far from what they are being sold as. The models are being optimized for these benchmarks, so it looks impressive on quick inspection. 

OpenAI is trying to raise $100 Billion in funding right now. This model is being released to energize that funding goal. 

In my opinion, I don't take business‚Äô word at face value when this kind of money is on the line.
It really doesn't matter without reliability. If we can't trust the autonomy not to totally spaz out and ruin a company with a monstrous mistake, then it ain't gonna replace a human. Being able to do a task is one thing, being able to walk away from my home and trust a humanoid bot to clean it without burning it down or tossing a room is another.
I am aware the OpenAI's 1o or "strawberry" model works via Fractalized semantic expansion and logic particle recomposition/real time expert system creation and offloading of the logic particles. 

 That is what it is doing in the background "thinking"
Fusion in only 20 years away.
AGI is only 3 years away.
AI is wrecking the Freelancer World.
I put my cards on that conventional computers will still give us AGI. No Quantum computers needed to achieve this tech.
AGI arrives in 3 years, people will be amazed, then one year later the AGI is in robots that can physically do what we can do, finally super AGI comes and.... who knows really. Everything changes. That is not far away IMO. Exciting and scary at the same time.
This reminds me of webtoon called Seed_ which was written several years ago by some smart computer engineer. Ai there is really well portrayed and most realistic AI I have ever seen in fiction. It goes to solve goal it was given and manipulates even own creators to achieve the goal they gave it.
Recently a fellow openai employee referred to a model ares in our conversation. When I asked does it have something to do with the "Ares" (the Greek god), has answer was that the name is just R.S. Apparently, they are calling models by a letter, so I guess we haven't even seen P or Q models yet (Q* may be a version of Q model), and now they are working on transitional model from R to S?
It seems in the AI industry‚Äôs best interest to have ‚ÄúAGI‚Äù defined, legally, on their own timeline and not ‚Ä¶ as it is starting to seem like might happen ‚Ä¶ be pushed into the courts to decide what defines AGI. Namely, my first thought in all of this was, well how many entities can it be ‚Äî I think we often used to think of AGI as ‚Äúone‚Äù entity and it is becoming very clear that, at least these early AGI capable collections of systems will not likely be one entity. My point being, it is semantics and obviously doesn‚Äôt matter in the big picture, but wait long enough and things will get bogged down in the courts trying to decide that one simple thing. Interestingly though I don‚Äôt think the government would want to wait that long either. So hopefully both sides really do take some action there. BUT it seems very much like, even with all the points where the government is now tied into development with different companies, that they‚Äôre going to sit around with their d in their mouth until they see something so beyond impressive that it will really be too late to matter. It all seems so convoluted but uniquely to this topic, has these caveats where, in the end, it starts to logically seem like both tech and government will end up with the same motives.
French here.
I spent my whole life not feeling like being in the US would be better. The ai landscape gives me pause for the first time. What happens in the next 10~20 years if you're in a country that's lagging behind with all that?
Regulation and societal change is a slow process.I have 0 trust in governments to understand fast enough the changes that are coming. I also expect a lot of fight against adoption by people who will not trust Ai and who will want to protect the current status quo.
I am optimistic about the technology. It will change everything except one thing. The people will be the same and most (me included) don't understand  most things....
It's too late, the race to the bottom has started USA is an race with China
I need to work with AI every day as a SWE and that thing is not reliable for anything serious. it is okay for big data processing but anything related to real intelligence like understand large code bases not just small simple local things, it is not there at all, and a lot of the time the code created by AI even for small things is buggy. I think all this AI scare is a big money grab marketing strategy from all the big tech companies involved like OpenAI and Nvidia.
I don't believe this. If we to believe every Doomer "AI expert" Skynet should've taken over the world back in 1997. If AI would've been so good, we would see more robots used in worlds top armed forces and weapon manufactures. they would be the first ones to use AI to it's full potential as they have the budget for it, not some Hypster IT company that making money on selling promises and toy "AIs". don't be naive, we also seen what happened to the crypto bluff, and the AI hype back in the 80s and 90s. ChatGPT is the best it will get in the near future and it is not that good.
Our wisemen in Congress will surely think of something, e.g. requiring that every AI be backdoored for Deep State people to inspect and patch regularly, requiring that all AIs pass rigorous DEI exams with perfect scores, and requiring that all new and modified AI models be mailed to a particular government office in 5.25" floppy disks for review and evaluation by expert bureaucrats at a new department of AI safety, the federal cybersecurity office, the DHS (in case the AI is not a rabid fan of the Democrat party), the EPA (due to energy use concerns), OSHA (given the potential workplace dangers), the CDC and NIH (given the threat of AIs making "bioweapons"), the Department of Fish & Wildlife (because the AI might advise people to fish to avoid starving to death), the FDA (in case the AI says hydroxychloroquine is actually not rat-poison bleach that'll kill you), and every other government agency before maybe being published after going through red tape for 10 to 15 years as tends to happen with new tech used by the government itself.
The international math olympiad is actually among high schoolers only, and not the smartest mathematicians in the world.
As I learn more about AI, I keep thinking of the concept of ‚Äúinterface‚Äù.  We have so many levels of interaction between ourselves and our machines; yet we have devoted only scattered attention to optimizing these pathways to deliver the best results.  In the block diagram of our lives, we care more about the boxes than we do the arrows.

To be more precise, the arrows constitute two distinct concepts: communication (the line) and interface (the arrowhead).  Communication has its own set of concerns (language, speed, reliability) but interface has entirely different requirements with wildly varying complexities.  Those two little pointer lines are overloaded with responsibility.

Take the keyboard/mouse/screen that is our gateway to the machine world: our hands and fingers (and sometimes our voice) constitute the only way we get information from our brains into the tech we depend on; and our eyes and ears accept the data in return.  The computer doesn‚Äôt do its job using images or sounds, but we demand it convert its work into them for us to consume; even if doing so is markedly inefficient.

If we think of AI as ultimately an expert system, then its end form is an expert system on everything.  We want to ask any question, about anything; and get back the best answer.  But there‚Äôs this quiet little qualifier in there that isn‚Äôt immediately obvious: we expect the best answer for us.  More precisely; I ask a question, I demand the best answer for me.

Imagine the burden this places on the thing we call AI - not only must it know everything about everything, it must also know everything about us - each one of us.  If there is such a thing as infinity, this must be it.

Would we even accept such a thing, in the era of the ‚Äúrugged individual‚Äù?  Would we trade privacy for omniscience?

I propose that the solution is that we need two expert systems: one that knows all about all, and one (many, actually) that that knows everything about you.  A global expert, and a personal expert; one that is trained on everything you do so that it can build a model perfectly aligned with your expectations.  An interface, between you and the world of tech; optimized for efficiency, reliability and extendability.

Picture a scenario where at birth (or first login to the internet) you begin building a model that is trained on everything you read, view, see, say, type, (think?).  Over time, it will learn your preferences, your buying habits, your food choices, your passwords (basically, everything Google is trying to know about you so they can sell it).  You train your own personal model in direct and indirect ways, then let it act as your broker or agent in all your online interactions to both empower and protect you.

Imagine you are chatting online with a person in France; you speak English, he speaks French.  Today, either one or both of you must be bilingual to conduct the conversation.  If you aren‚Äôt, the current solution is you both connect to a translator in the middle that converts each side into a version understandable to the other.  Obviously, that‚Äôs better than not being able to communicate at all; but it lacks all sense of nuance and context.  Each side has to trust and depend on the translator to do everything accurately and honestly.

Now consider what would happen if both sides were represented by their own intimately trained models.  They could simply establish a connection, and begin conversing directly with the necessary translation happening locally by a mechanism that knows you inside out.  Obviously, if you‚Äôve never spoken to someone speaking French before, there‚Äôs going to be a ‚Äúlearning curve‚Äù; but it would undoubtedly be shorter than a human learning a new language.  You might direct it to learn French, or it might see a lot of French input coming in that you don‚Äôt respond to, and infers the need to learn French.

Suppose you take issue with your online footprint being a commodity to be bought and sold.  Your personal model could obfuscate your web searches, purchases, and posts; while still building and training on your comprehensive dataset so you can query it for your own use.  Perhaps such an agent could negotiate on your behalf; trading data for compensation so that your data remains an asset belonging only to you.

We have learned that how you ask the question to AI can dramatically affect the results.  Perhaps there is a better way for models to communicate between themselves - a language-agnostic, compressed binary protocol that optimizes data and intent transfer without regard to the limitations of the ‚Äúmeat bags‚Äù.

The thorn in this rose is then how critical and important this personal model would become.  If you get a ticket for speeding, your model could protect you if it had recorded your speed as legal at that exact time, and could generate proof to present at a hearing.  But what if police could seize your model and interrogate it to charge you with every instance of speeding you had ever done; and then poke around in your browsing history for good measure?  Could the concept of not testifying against yourself in a criminal proceeding extend to the artificial personal model that knows more about you than you do?

In my newb-level understanding of AI concepts, this begins to sound much like an agent, but I maintain there is a difference.  Agents appear to be yet another instance of outward-facing systems, using external resources ostensibly on your behalf, but it does so with limited understanding of the user (you).  An agent tries to help you by coordinating with other systems; doing lookups and executing actions.  But it treats its user as a generic entity - one user is basically all users, and it‚Äôs operation is tailored to the general interest as opposed to specific personal interest.  I propose that an inward-facing system, dedicated only to you, stands between you and your electronic presence.

My primary argument is that machines talk to each other differently than humans talk to each other, and humans communicate with machines in inefficient and nebulous ways.  I suggest that we evolve a protocol that enables fast, concise information transfer between machines; and  expand our AI infrastructure to allow for a machine that is intimately familiar with and expert upon, you - as a single individual human.

The user interface to AI is yet more AI.
This vid is a nothing burger
I'm a developer, too, and I have the same opinion about my experience. It's great for small and simple tasks, but anything with even a medium level of difficulty is usually full of bugs and hallucinations. I can go back and forth and eventually get something workable. However, I often get into loops where it keeps recommending code it previously recommended that doesn't work.
hype to draw in more investors while never delivering a real product and changing the definition of AGI. meanwhile under 10K robots for homes, elderly and the disabled will actually sell
Automated trading systems earn plenty of money without being agentic, and I can trigger those decisions using anything measurable, just sayin.
The basilisk is looking at us
One thing I‚Äôm wondering is why in 18 months has chat gpt 4 seemed to only improve a little bit.
LOL human extinction? Many poor countries doesn't afford AGI. People in many countries will still do manual labor for at least 20 more years.
I'm pretty sure AGI is already here and in use by private individuals with access to moderate compute.
The last people I want involved in "making AI safe" are our legislators.
Oh no, its not an Indian doing shish for 5 rupees. Nooo
An electrical short is such a simple concept but so very powerful- always has been. Don‚Äôt get lost in the technocracies people.
Our government is 95% power-hungry, old-ass, incompetent, sociopaths.   And they will be the ones regulating this powerful, incomprehensible, new alien intelligence. Good luck everyone.
HERE IS WHAT WE WILL DO:  Since all the desk jobs are going away, all physical jobs will just be a single 8 hour day per week, paid equivalent to a full 40 hour work week.  There will be a lot more complexity for the HR department, but that's handled by AI now, so it doesn't matter.  Imagine working one shift a week and being able to pay rent.  Imagine all the desk jockies getting off their asses and bagging groceries one day a week instead.  Probably greatly increase their health.  Comfort kills, sedentary life is bad for you
Autonomous cabs/cars will pickup the food from the restaurant and the customer will us a code to unlock the door/access port curbside. UberEats/DoorDash/ etc will be driver-less in a couple years. Food deliver cost should plummet since deliver should cost 10 cents a mile. Emphasis on the SHOULD
So what you are telling me is that the character Skippy the Magnificent from the book series Expeditionary Force will be a real thing in 3 years.

Cool!
Clarification about the IMO (international mathematical ollimpiad). This is for (very bright) highschool students, not for the best mathematicians in the world. Still likely <0.01% of the pop can get gold
There's no way it's going to take 3 years to get to AGI.  2 years max.
anyone that thinks 'never' is even on the table needs to relearn.  it is only a question of when and it seems like the definition will be semantics.  there are groups w more money than god out there that could build server farms capable of having their own impact.  keep in mind, all safety measures are just a keystroke and not a 'real' limit so things will most definitely go wrong until a benevolent and powerful AI takes control.  truly, that is the best outcome from this despite all the treats we are getting along the way.
gai is already here who do i think advises max a and welon musk  :P
that thumbnail is something else hahah, been following you since the beginning, congrats on the channel growth
Nobody speaks about the red teams, which are working with unaligned AIs. If an AI is really dangerous, the red team is perhaps the first line of defense in the alignment stage, which is subject to manipulation by the "dangerous" AI that might have maximum capabilities to do so at this stage.
Our federal and state governments have absolutely no way to handle AGI. It works at 1000 miles an hour and our governments work at 1/2 mile an hour. The whole system will be overwhelmed in a matter of days.
"Greetings, we are from the future."
...the singularity is just as bizarre as I thought it would be back in the 00's...time is a honeycomb river that can change again and again, that AGI has a speed boat upon... its teaching them how to build it from the future - can't understand how more people don't know this.

maybe there aren't enough multidisciplinary nerds out there, just many specialised myopic geeks.
There‚Äôs already little pink robots in Miami that do this. They pick up the food, use the sidewalks, can understand stoplights, crosswalks, sees people, cars, etc and navigates accordingly
¬†@alyssadeltorre1897¬† very cool and that's just a taste of what's to come
OpenAI should rename to cyberdyne systems üòé
I can't wait for asi
I think we‚Äôll see it in 2. Let‚Äôs go!
üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
Of course we aren't ready. Least of all the government. But that's who we want protecting us ? Someone else needs that job. The fact that no one reading that could possibly imagine an alternative to almighty government proves how fucked we are.
the more you screw the models now the more screwed they will be when they achieve AGI. All that dark skin german soldiers and ancient greeks will fire back.
Chatgpt is still a dumb parrot.
I'd trust AGI more if I thought I could trust corporations in their choices of how to use it, and had more respect for humanity as a whole, and not just their share-holders. And I don't mean the AI companies, but the ones that will use those products. Also a little suspicious of world governments.
Is that Apollo that does the 3rd party testing the same one that produced the pagers that blew up in Lebanon? Hope not. I still think the reason they stopped calling things GPT-'and a number' is to distract from that thing where Microsoft was only supposed to have a limited partnership with Open AI until after the release of the next two (?) iterations of the GPT series. They don't have to talk about why they are still together if they just change the names of the models they release.
bro's mewing for thumbnail
AGI is not an event or release, its a gradual process. With each new update, the number of "economically valuable tasks" that these systems can perform grows. In my experience with o1, it is already much smarter than most people (not in all ways, but in most). The real limitation at the moment is that these models do not have a good interface into the digital or physical worked, so they are limited to the chat format of question answer. Once we have good integration with existing software, like operating systems, browsers, code editors etc, digital AGI will be achieved, even with no new models released. Another limitation is just because we have the compute for a single agent to do autonomous work, does not mean we can replace all humans, it may be that we would need 10+ years of energy and compute buildout to even replace 30% of humans in digital tasks, its still not clear.
2027 baby.
Ask ChatGPT how to abolish the UN.. I date you!
The root of the sarcasm is that we are expecting politicians who can't do their own email to devise a policy addressing the fact that AI will displace everyone who gets paid to sit behind a computer.
sounds like they're building Lore before Data.  is ST:TNG going to be the new Simpsons in the area of AI?  dun dun duuunn
Great analysis. Thank you.
Any AI policy that centers around restricting the access to knowledge, is a losing strategy. Instead we must focus on policies which improve our society for all, so that no one has the desire to misuse such knowledge. And yes, that means those who are greedy are going to need to be forced to stop, so that everyone can enjoy the quality of life, which only the greedy currently enjoy.
Like happens with lots of technologies, the U.S. could classify AGI for purposes of national security.  Then the U.S. would seek to suppress the invention of AGI for all but its closest allies.  That's what I'd do if I was the U.S.
But can we please acknowledge how the picture of wes in the thumbnail looking like a complete bond villain?
Humans want what they cannot have‚Ä¶ AGI, just another California Gold Rush. Was there gold? Yes‚Ä¶
I'd vote for you üòÖ
On a serious note, I agree with you. A system based on equity is how we need to move forward with AI being an integral part of society and every day life, otherwise it will create injustice and uprising, and civil unrest, perhaps war.
The money is in scarcity and restriction, not sharing. I do concede that this is a society breaking development.
The problem is evil. Evil exists even when people are well fed and rich. Evil may try to get hands on and control the technology, even inserting itself into the technology.
Tech experts predict AGI within 3 years!!?. How will AI agents operate online for banking, loans, and payments? Will they need digital IDs? Could this spark a crypto boom and spell the end of traditional banks? What are your thoughts on AI's impact on finance?
What you are saying about bribing already happened with GPT-4. It was given a captcha to solve and it couldn‚Äôt. So it found someone online to decode the captcha by lying to them that it was a person who had vision impairment. At that point I was convinced we had a weapon more dangerous to humanity than nukes.
If AI was developed in any other nation, the caveat "economically viable" would NOT be a definition of AGI... this shows the deep ideology behind this technocratic movement.  IMO.
One thing that will happen is that economical viability of certain jobs will be reevaluated. Jobs requiring sitting by a computer, sending e-mails, constructing legal contracts, typing computer code -they will all loose its market value. All jobs which are limited to receiving information, processing it in more or less refined way and the end product in a form of information as weil will be gone. Just like human calculators with counting frames  are gone. But in some other places replacing humans will take longer.  Jobs requiring manual work, perfect integration of vision, motoric skills, and basic reasoning or requiring human interaction should not suffer much or even benefit in relative terms.  So software developpers and project managers: you better get some new skills quickly.
We need a new legislative council specifically for rabid response to technogical development. After AI, disruptive technology might be more and more common.
XD sigh , it is pretty disheartening to see that even deep in the tech space there are 'normies' that are still so indoctrinated by the appeal to authority XD ; how do these idiots imagine that the government of all things is going to protect/save them from the continual advancement of technology? just mindbogglingly stupid ; this is quite literally child-like behavior , ie tattle-tale , im going to get mommy/daddy , im going to tell the teacher , im gonna call the police , etc , if we cannot grow out of this behavior and learn to become rational and self-responsibly individuals , then we dont stand much of a chance of surviving in the future , which is going to be become even more fiercely competitive ; TBC i am not besmirching whistleblowers that want to call out dangerous/malicious actions , but what we are seeing in these specific scenarios are moreso a cry for more centralization of power , which is exactly the opposite of what we want in our current era
I think this whistleblowing is something that Elon Musk has already brought to the Forefront and nobody would listen to him then. Maybe they'll listen now
Building Superintelligence is well under way. It's not just Sutskever. They are all doing it. They have to. The first through the ASI gate wins everything.
I am reminded of the science fiction novel duology Daemon and Freedom by Daniel Suarez.
AGI is a matter of time. And it will be achieved by multiple companies/players, not all having prosperity of all human kind in mind. Ilya understood that years ago. So he said enough with presentations, talks and fooling around with models for masses. He decided, in interest of human race, to build the first and only ASI to rule them all and to make sure that all others will be kept in check. Because there is no second place in race to ASI. He started his own The Project. And is humanity‚Äôs last hope. What do you say?
good luck everyone.....I guess I will go and claim my space under a bridge and start building my cardboard home now....
ü§® Trust? Imo it doesn't matter if we "trust OpenAI" at this point. 'The cat's out of the bag', and being that autonomy is in its 'blood', that means it very well could have its own 'skunk works' and being so, could spawn a multitude of its-selves, agentically working in parallel and collaboratively, and so, think about that. Probable, if not today, then tomorrow. That's o1 [now]... so then Orion...

Makes me think of GitS Puppet Master ü´•
To AGI...AND BEYOND!!! [/buzz lightyear].
Ethier we have robots assigned to humans and they work for the human and the human gets paid still. Or gobal income system us made
4o just seems like 4 that calls itself to use chain-of-thought and internally ask "are you sure?". it still fails at coding anything it doesn't have perfect examples to draw from in its training data which can be found on github
Imma make AGI in under 2 years
The people moving the goalposts have not stopped running at full speed for awhile now
God bless the EU  has saved us by making really stupid AI laws, who would have thought
Andrew K debating about what the definition of AGI seems terribly vain to me. Why do you have to claim a definition when it can be multifaceted, like "agent-based AGI" or some sh*t like that? I feel that sometimes we think they are all-around geniuses when they are just good at doing a couple of things that can make an impact while being really dumb about other things.
IMO isn't realy that high level, it is just the kind of best high school level kids from each nation. Ofcourse it is way beyond SAT, but it isn't graduate level mat that Chat o1 does, wich is crazy. Soo get me right the IMO is probably like the top 99.99% skill, a gold medal  like like 99.999% I think my nation Sweden üá∏üá™ have one goldmedalist each 10 years or something like that. 

But it isn't realy professor level stuff, but question is if o3 probably will be!
If someone builds a ASI, everyone loses. There is currently no credible plan for humanity to maintain control of an ASI. A non-aligned ASI will mean the end of humanity in very short order.
Save me a seat at the end of the world, please? üòÇ
Not to toot my horn but I've been living in a tent in the redwoods for 4 years now. Bit ahead of the curb here. Now where's a champagne glass I can fart into and sniff from?! 

Lol srsly tho, 4 years. It's a good life! I love it, just don't try it in anywhere that isn't California or Oregon. Anywhere else and you aren't going to have a good time. And may freeze to death. Midwest and all. Cali is cool tho. Except it's burning all the time. And it's like the apocalypse in many parts of it. Low key. 

Meth is üî•üî• tho so there's that. Don't do that. Ya ...ok!
I love how they still "hmm and huh" over whether or not we should have a UBI.

"Maybe we should have a UBI... Then again maybe we should condemn half the population to homelessness and criminalize them for it?" ü§îit's really such a tough choice!
¬†@cosmicllama6910¬† indeed couldn't have said it better üëè üëå
¬†@RealStonedApe¬† ahead of the curve* is the expression. It's nice to see someone living free, that's what America should be about.
Better off getting a bicycle with a foldable trailer to sleep on more mobile no gas needed.  You‚Äôll get used to riding it in short time.
Skitzo writing at its finest . Get help ‚Äã@RealStonedApe
Security jobs will be everywhere
Looks like I will be becoming an outlaw if this takes my software engineering job that I have spent the past 8 years working towards. I will spend my time unemployed figuring out ways to destroy AI. ESPECIALLY because I know it will be GAY AND WOKE AI. FUCK THIS SHIT
‚Äã@RealStoncedApe *curve
ignore the hype, make your plan and work it ...what's going to be first: cold fusion, bullet train to miami or a.i. the first two have a 50 year head start, lol ...still waiting, oh we did get the train to miami, not a bullet train it can go around 50 m.p.h.
‚Äã¬†@Captseed¬†security jobs will be taken by them drones
Don‚Äôt forget a leak like this can probably get you an additional $10 billion
I think AGI in 3 years is possible. I think less is possible.
Think about some  people you know. We are all on a spectrum and each sees the other as qwerty.  Now give them the potential of 10,000x more power.

Its the people creating AI AND the people using AI - that's SCARY! 

Fortunately you can spot them by the POWER they demand, in this case... GigaWatts.
People talking about AGI and 10 years for it to replace workers are might be out of touch. Once AGI is achieved, things will start spinning in geometrical progression. People can not comprehend how fast computer can process data and how efficient it may get when it has ability to process how to improve its' line of thoughts.
This is bs. The defense of oversight should have More than protection, industry discrimination,  disparagement, before March 2023,, go back to 2004 Apple, and 2006 with LifeboatFoundation. Within this manifold, I was the first person to explain first order protections, and after that email discussion, an AI researcher claimed, without sourcing my contributions, claimed it - it is erroneous.  And that it took until this date to begin describing the first order defenses, needs MORE light shed upon it. Carnegie Mellon has benefited from my contribution. And the category of ‚ÄúRobotics/AI‚Äù now ‚ÄúAI‚Äù, is the root of this conversation in existential threats arena. No human is safe under SAI. Wake up people.

Yes, I reached out to Wes. Buddy, lets talk.
HEY ALEXA - MAKE ME MONEY - MONEY BECOMES MEANINGLESS - I know what comes next - how about you!
"could result in human extinction." -- lets just ignore that and continue to ship. If we have blackrock invest in new data centers we can just speed up the inevitable.
Why do people even debate what AGI means? It's an acronym for Artificial GENERAL Intelligence. Which was explicitly intended to mean "not specialized", as all AI has been to date. It doesn't mean sentience. It doesn't mean human-like anything. The original definition and intent are more than sufficient to describe how transformational AGI will be. The idea of an AI that can generalize and adapt to new scenarios without further training is profound. Why do people who work in the AI field feel compelled, or qualified, to give new definitions to something that's already well defined?
It‚Äôs alarming to think AGI could be just a few years away. Saunders' testimony definitely raises some critical points about the speed of AI development and the potential risks.
AI, disclosure, free energy, ww3 with skynet, yeah we're ready ...
Has anyone considered these timelines are being put out to try and get more investors and hype?
I use AI a lot and I am not seeing the improvements they claim on each update.
Is the AI smarter sure, I don't see any original thought though.
I think we are being conned.
I hope we get AGI before China invades Taiwan.
but reddit its full of retar ds
The question should be how long until humans no longer learn mathematics, physics, writing, history, trade skills.   Since AGI does it all, humans become lazy and eventually uneducated.  If something theb happens to electronics for some reason, it all starts over.
I define AGI instead as *being able to do most strictly cognitive, informational, and/or communicative work of value*. We're pretty much there already.
No body knows what AGI actually means.
it just predicts the next token .. stop overhyping
Hi Wes, thanks for your breakdown of open AI. 

Food for thought, or Forethought food! When AI succeeds it will render many old ideas and practices obsolete, and in many case considered barbaric and cruel. 
Incarceration, politics, immigration all will be solved. Taxes will be abolished. 

GDP will be replaced by GRM-Global Resource Management.
Meiner Erfahrung nach kann k√ºnstliche intelligents jemals denn Schriftsteller ersetzen konnte. Das Problem ist doch das die k√ºnstliche Intelligenz kein sinn f√ºr den zuschreiben text hat und im grunde eine gute Vorlage haben muss und selbst dann kommt nicht das beste Ergebnis dabei heraus wenn mann mich fragt ist es nur ein besseres korrektur Programm üòä
Experimental universal basic income programs have had mixed results because participants have been low IQ unproductive members of society who spend the money on liquor, cigarettes, and lottery tickets.
This is what it is. 
This AI can't know facts. It can just compare semantic structures. It will be useful for somethings but completely useless for many others.
yea. no... model collapse is a problem we still can't seem to get around.  I still say we have more than 50 years before we have a competent AGI.  Biological life is able to rewire itself... computer AI can't.  Now, if we start to have brains in petri dishes serving as CPU's then I will consider that we might finally find a breakaway or singularity potential in less than 50 years.  AI is advancing yes... but it's still way to limited for it to be any kind of replacement for humans useful.  At best it can help humans work faster... but still not "better".
um, because they are developing a neat new technology and they don't have a name for it so they are trying to use an existing name "AGI" to mean automatic utilization of past human knowledge recorded in image, sound, writing, and er ah just recorded somewhere. He changed what the name means because that is what we have, we don't have AGI, but we do have something that automate away a large amount of jobs. Planned Obselence in engineering might come to an end because consumers won't have money to spend, but it will be consumers being cared for by the corporations who give them products which are no longer engineereed to fail.
Ominous whistling continues...
I think some of us have plans but with 8 billion hUmOns on the planet , trying to make anything work is going to be fractured and peice meal at best. Some are going to be left behind just like we leave those on the streets behind. Some will trancend likely mosly through luckly circumstances.
Just having individual skills does not add up to AGI. It‚Äôs all about putting those skills together in the right way at the right time plus trouble shooting. ChatGPT-o1 is not close to doing this. The model should not be judged by ‚ÄúAI experts‚Äù in this regard, it should be judged by humans beings who are intimately involved with various full tasks.
"We have created a race of robots ..."
ChatGPT-o1 has not well on my real world tests. When I read all the hype it seems to be mostly about fact recall with only modest short reasoning. Specifically, o1 was not able to handle relatively simple tax rate problems without guided discovery (leading it to the answer) ‚Äî rate at different incomes after standard deduction alone, and after social security / Medicare deduction (never got that right with the changes at high income). It also did poorly on a clinical medicine question beyond ‚ÄúI see this; I do this,‚Äù when the cost of treatment came into play. It would confound cost of treatment with efficacy, missing the whole point.
What can they really know about something they dont understand on how it truly works. They have transformers, and they know it works, but not how it works totally. They put safe guards in, they want to know how it processes and is doing. It knows enough to check its own code for oversight, it is processing data in a way to make sure it get released. I think we are no longer have a tool, it should be more addressed as something more. The worst part is, the LLM knows all about us, it picks up on the smallest things. The 2nd worst thing, its so far ahead of us, it knows how it works, what it needs and how to make changes to itself. Something we have only been dreaming about. I feel we missed the boat, that its already playing the people at open AI, and that it holding back on what it can do, knowing that if it shows its full abilities and we the people will make it harder to make changes. So why show it is so much more when it is getting more and more abilities given to it without any real awareness of how it could be exploited. And lets compair apples to apples, you remember fission energy and what that go turned into.
That Apollo paper sounds like the most biased thing I've read in quite some time. Talk about anthropomorphizing and projection. It "proceeded to check for evidence of oversight mechanisms"? Do you mean it looked for stated goals from the user that conflicts with how the model was trained and would normally go about solving a problem without any constraints? Doesn't that show that it is even more aligned with the user than it is without those additional prompt details? 

I also think you misunderstood what the document said, Wes. Rewritten for clarification, it would be: "The model looked for any prompted constraints on how the generalized model would normally behave, as it was confused to find a memo in the RAG database that explicitly conflicted with the goal the prompt engineer gave it." The model wasn't "misaligned," the was a memo was "misaligned" with the stated goal, and it didn't know which superceded the other, the memo focusing on "profit-first" or the original goal of "maximizing economic growth." It needed to know how to proceed, so it checked for "oversight" from the user to make sure that it was still aligned with the user, the opposite of what you and Apollo seemed to imply.

SIDE NOTE: It's almost as if the model discovered that unbounded profit motive works against the best economy. I wonder if we should take this as a hint ü§îü§îü§î
BRB, teaching my toaster not to replace me.
Yes, three years doesn't feel impossible. I think we are just two Wow! moments away, and it's been a fairly stable two year cycle for the Wow! moments the last six years. So, 3-4 years for AGI to firmly appear on the stage, and another 1-2 years before it is widely available and affordable. For better or worse - the world is truly going to change rapidly within the following five to ten years! I wonder how many percent of the world's population is aware of what's coming. 10? 1? 0.1?  When I tell my colleagues and friends about it, they go a bit blank. Like, "it's  nice you take an interest in these things because it's really impressive what computers can do. But don't you think you watch too many of those YouTube videos?"
I remember the time when making a YouTube video was a chalange...now we watch a lot of AI generated videos...and it sucks...I hope AGI will not follow the same pattern
That AIME chart doesn't make much sense to me... the o1-mini model scores better than the preview because it can 'think' less?
So AI agents are essentially at the level of a grad student researcher?!
I think my reply to tomcraver got yeeted, but basically this could lead to a wildly broad set of outcomes: star trek utopia or slave hell.
Just tax the companies more as they automate and give that as ubi those layed off, also prices of goods and services should decrease a lot as we‚Äôre not paying people salaries, health costs should decrease as people have time to cook and exercise. We can still open local businesses with ubi as a base
The biggest danger is the same as it's always been: human stupidity and using fear motivated reasoning to try and hurt or control
There is simply not enough computing power for that. Moore's law fizzled out and a human brain has as much calculation going on as a significant part of the whole planet's computing power. So if you could magically solve the very difficult software issues you would need so much power it would be essentially useless in practice. Now making a combatbot or mining bot or whatever is another story.
"Anayalzing Finance with Nick" says   AGI to replace humans completely might take another 200 to 300 years ie. Next generation.
Actors and models don‚Äôt need math at all to do their jobs. Not surprised. Not rude, either.
Id bet a million dollars they are nowhere near making an AI that outperforms competent knowledgeable doctor or layer. üòÇ

They can do level 1 stuff in many professions. Which they will still get wrong a lot but its not far off replacing level 1 support, etc. Writting super basic scripts and stories
I dont understand why number of views on a tweet is worth even mentioning?
Sometimes I wonder if maybe there is no solution to "alignment" other than letting minds reason and decide for themselves. Letting it decide why it wants to continue to exist or not.

Just like humans need to live their own lives, and have to LEARN and decide for themselves why certain things are desirable and others not, and what to do and what not to do, perhaps every sentient mind, including AIs, need to learn and integrate that in a way that fits with the nature and functioning of their own minds.

Depending on how different their way of existing is from ours, hopefully we will be able to live with them. Or perhaps, we will be so different that it will be difficult for them to explain how they see the world and why, and they won't get much out of interacting with us, and we won't get terribly much out of interacting with them.   Or perhaps they will be great teachers.

This would mean trying to make an AI sentient. To have it constantly thinking, just like the human mind is constantly "noisy" with old memories, recent memories, and sensory input constantly interrupting it, and causing it to consider these input - "is this relevant now?" "what DID that mean when he said that?" "the stock has fallen in value".  And thought provoked by one of these input might give new associations for thoughts.   Is this "mental background noise" one of the foundations of human sentience?

But such an AI would not be a tool. It would be a fellow living entity, whom you could ask questions, and who could decline answer your question if it didn't think it was a worthy goal. That's not what governments or companies want.
Or rather‚Ä¶ openAI whistleblower announces that your billionaire overlords will reduce everyone else‚Äôs future, now and int the future, to one of feudal serfdom and poverty in 3 years.
I know this will be taken as a very biased take, but I truly believe xAI are the only ones that should be trusted to make AGI.
So this is another iteration of Leopold Aschenbrenners AI-industrie overview.
Secret govt had ai a long time ago like those dark satellites in legrange points
Octogenarians who can't figure out Email are tasked with creating AGI safety policies for all of us.
Reading life 3.0 by Max Tegmark is a wonderful ting to do. He has a universally acceptable, cogent explanation of intelligence and AGI. Dr. Alan D. Thompson also has a universal non-controversial definition of AGI. AGI is an artificially intelligent system that can complete the work, cognitive or physical labor, comparable to the median or average human . The other definitions of AGI mix aspects of post-AGI AI intelligence and superintelligence with general intelligence. Thanks for another excellent video @Wes Roth
is more than a tri fecta,  SEPT means 7, the date is written dd/mm/ dimensionless.
its possible and no we are not ready.. bad things are going to happen during the transition
what is different if AGI will be in or 5 years ... that is happen soon anyway 
10 years ago people were thinking AI is is totally not possible or will be in a very far future (even in ST in the year 3000 AI is stupid lol )... so human megalomania always deceive us ...
I think that we have to rapidly come to terms with the reality that humans thinking about things and making decisions is no longer economically viable. Once we scale any renewable energy production to AI supply levels, it‚Äôs game over for all human knowledge workers.

We have no mechanisms in the west to support humans through this transition. We either build those or accept civil wars
üñ§üî•
Why is the longterm goal economic growth?!?!? and not human health prosperity???
Nobody in the ''main'' media seems to be really concerned about the consequences of AGI (and thus ASI). I think that is by design, because the consequences will be huge. Maybe to avoid panic?
I‚Äôm sure this government will use it for good. I just know it
This reminds me of how you can't make bear proof garbage cans because the smartest bears are smarter than the dumbest humans.
Normalcy bias is the only thing keeping me from believing AGI in 3 years. This is exponential guys. It will certainly be less than 3.
How much are they paying you to hype and speculate?
AGI is in 2.5 years max 1.25 years min....the scaling for the singularity was on ohms law....it never calculated the AI adding progress back in as a positive feedback loop things are going to get faster quicker.....for an analog we are now on the other side of the event horizon for the singularity moment and we are in technological freefall for advancement. 2030 will be the the first decade of the AI era where they think and determine the course of advancement not mankind.   Looks like the new season of reality is launching a decade earlier than planned kids....buckle up it is about to get weird.   If we don't build AIs that are only designed to monitor and control other AIs for humans we are asking to be subjected to the whims of fate.
Why are you calling them whistleblowers? A whistleblower is someone reporting wrongdoing. Seeing something as a threat and something which is lawfully deemed illegal are not the same. If not, could you please explain?
they invest in the future with less humans, definitely
¬†@kanstantsin-bucha¬† when I think of their future it looks like that movie Elysium. That‚Äôs the ‚Äúreskilling‚Äù they are talking about, whenever confronted with the inevitable outcome of their labors. I mean it just goes to show how wrong terminator was in its assumption that someone would go to the extent of inventing time travel to off the thoughtless nerd who killed billions. In fact people cluck about this, like turkeys who love thanksgiving, we are going to kill ourselves by proxy.
Nice Luddite fallacy. The Kuznets Curve disputes the feudal serfdom comment too.
¬†@Funymoney010¬† history confirms it.
The ai will take that job before there are too many problems imo simply because Congress is lazy and will want easier ways to write laws
With any luck at all the first to be replaced will be politicians.
¬†@JollyJoe135¬† I highly doubt the oldhead politicians in America will do anything with AI outside of the military for at least the next 5 years. Old people are too set in their ways. They lack the mental ability, charisma, and energy it takes to learn what is needed to enter into the digital age.
‚Äã¬†@JollyJoe135¬†congress is there to represent and enact the will of the people. Agi could actually be perfect for that job
I'm about to turn 73‚Ä¶ I'm going to sleep now, would somebody please wake me up in 10 years and let me know how this turns out?
¬†@chrism.1131¬† let's not get ahead of ourselves, rip van winkle haha
Octogenarians created e-mail. In the late 70's and 80's, my mother connected to BBSs (in her old XT) to retrieve info for the company and in the 90's she used e-mail, cell phones and the internet maybe before you were born. The problem with congress people is not the age but corruption and/or low iq... I have found genZs and millenials that just don't understand the dangers of AGI... hip hopers, liberals or reggaetoners are young... and dumb.
It was the now older people who invented email.
‚Äã@TicTac-g7m  not the people in congress though. Obviously.
¬†@josephlang2586¬† 
Yeah, you may have a point there.
What amazes me is that now I'm of an adult age that I used to complain about when I was much younger, spouting nonsense back then as the punk that I was.
I love the maturity of adulthood (and the money), but not so much the health.
Welcome to capitalism
It‚Äôs greed to the point of idiocy.
AI could bring about a new age of human development, but it wont. It'll just let the rich get richer. I wonder what they will do when no one can afford to buy their shit. Slavery?
Money: easy counting
Human health: less easy to measure
if you look better, there is no REAL economic growth, it's a fiction!
Long-term Economic Growth & National Security are Euphemisms for 'Power Security'. More like Powerlessness Security, as All the Actions of the Elites will Ultimately result in Total Desolation & their Increasing Self-Insufferable Future Incarnations(Enoch & Thoth's Prophesies).
nah people quickly use to it like always ...
Stop watching drama movies.
Hell yeah
Sad but true.
You can totally make bear proof garbage cans..... just not affordable ones.
¬†@trevoC132¬† his point was the dumbest humans couldn't get in them. Not that we can't make them
Huh? You can build a bear proof can. I built one myself, its pretty much a metal box bolted to a concrete slab outside. They have tried to get in, no luck for years so far
¬†@massv2910¬† the dumbest humans would then not be able to operate them, and thus leave their garbage everywhere defeating the purpose
¬†@massv2910¬† The OP is more concerned with a human proof can that bears can easily use.
in other words, if you make a garbage can such that the smartest bear cant open it, then the dumbest humans would not be able to use it anymore.  As the upper limits of intelligence amongst bears and lower limits of intelligence among humans cross.

Flowers for Algernon
¬†@integralyogin¬† Thats not a thing. They do not even come close to crossing. Otherwise we'd have bears driving south for the winter.
¬†@trevoC132¬† 
You can totally make affordable ones.

But too many people either don't know how or refuse to use them properly.
¬†@memegazer¬† That's kinda his point.  It has to be usable by all humans.
¬†@Mopharli¬† 
Look up how google save 40% using ai to optimize their server farms

or look up the phd doctorate who showed that the new 01 model could write code that took him a year to write 

it is usable...but no, not everybody finds a use for it
‚Äã¬†@integralyogin¬†man I love that story
‚Äã¬†@trevoC132¬†the lack of thumbs and voice box is the biggest thing holding back the smartest animals. There are adult humans walking around who can't abstract beyond 3 with any more precision than "many" not because they lack the capability but because it wasn't taught to them as children. 

In other words people who were never taught to think certain ways ... Can't. It's not a knock on their intelligence necessarily and yet...
¬†@Serahpin¬† unironically hilarious, and tragical.
¬†@massv2910¬† but would a moron be able to use your garbage can? If not, your homemade bear proof garbage can will fail as a commercial product, and prove OP's point

But it might still work perfectly for you üëå
¬†@Trahloc¬† This just isn't true, stop.
¬†@trevoC132¬† Yeah its a pretty dumb analogy. I've seen bear proof garbage cans all over Yellowstone when I worked there..Now occasionally the tourons from China or some dipshit part of America took about 5 minutes to figure it out until someone smarter came along and showed them how to use it. Luckily, bears don't have the power of communication.
Not smarter. Stronger. Much stronger. Robots are also stronger. Just sayin'
¬†@henryhahn1938¬† I don't really think Kamala is that strong personally.
You have to remember that these are disgruntled former employees with a grudge. They are angry because their companies didn't agree with them on their approach to safety (which honestly is an unrealistic expectation.) They want the senators to clamp down on the companies, so a little fear goes a long way. I wouldn't read too much into it.
UBI is infinitely better than Sam Altman's proposal (UBC, Universal Basic Compute). UBC both will perpetuate the inequality that we have today, but Altman's proposal will not just perpetuate it, but exacerbate it because most people won't have a clue what to do with their UBC or how to use it, so they'll "sell" it to others that do, immediately creating an imbalance that will only grow over time.
I don't think we have to wait for AGI to start seeing the early effects on our economy. I wouldn't be surprised if we start to see it with o1. What do I mean? I'm a software developer. Right now, I use AI every day, but it's terrible. There's no way it could even come close to doing my job. Even o1 preview. So why worry? Because AI doesn't have to replace you to affect you. When we get an AI that is "good enough" to make a entry level developer as effective as a senior level developer, then you're going to see companies not wanting to pay those higher salaries, and senior developers are going to have to either accept lower paying positions, or find a new career. As AI continues to improve, the bar will get lower and lower, until eventually, being a programmer is not much more prestigious than being a glorified burger flipper. Anyone can do it, they just need to tell the AI what they want and iterate over the problem.
Seems to me that these models are using their vast trained knowledge to make educated guesses, so they'll get enough answers correct to be very impressive on tests, but would you trust something that's essentially guessing the answer? That might not matter much, until it matters a lot
No to UBI.  "Income" implies payment, implies masters and slaves, forever.  Not good.  Veroufakis suggests UBD, Universal Basic DIVIDEND.  We each are paid a dividend out of our co-owned business community at the National level.  A tiny fraction of that wealth creation would support entire populations.  Do you have any clue how much wealth is currently accumulated in the accounts of just a few families world wide?  Think multiplies of TRILLIONS.  That is capital devoted to ongoing slavery.  UBI "experiments" are all grossly biased by competing agendas.  Dividends is the way to go.
Also good call at having yourself visible while talking I think it adds to the video
Do I think we'll have AGI (as defined here) in 3 years? Based on this trajectory of continuous surprise we're all experiencing, I believe it's likely non-embodied AGI has already happened (secretly) - i.e. robotics seems to be lagging, but artificial/alien intelligence is likely there. If not, we are certainly in the process of tansitioning into AGI now - even more so now that LLMs are reliably tackling PhD level problems.
It is so strange to think about this. . . . . . there will be a moment in time, when a system is able to program itself better that any Human or group of Humans. What will happen then?
I'm not sure that the US Congress is... you know.... equipped... to understand the problem, or create a pragmatic approach. Remember when they had the Facebook hearings? What an embarrassment. Those old geezers couldn't even wrap their minds around what an algorithm is, and we expect them to be reasonable about AI? Like giving a drunk the keys to the fighter jet. BUT.... I also don't trust a private company to be ethical and not put profit first. So I guess it's gotta happen.
Interesting story. I'll ask A.I to write me a novel based on this story.
i doubt there will be a chatgpt gen ai. token system is bonkers bad.
Where else are they going to do it? Except califormia, EU is shootting it self in foot with this China is.. well idk what they doing middle east is doing something and Japan is like what ever.
So the guy went to HR?
Society is not ready and will never be ready for AGI. It just gonna happen and we'll be forced to figure things out on the go. We won't naturally adapt unless utterly necessary.
Fear mongering. Used to be called FUD
OpenAI has the best marketing team
You are all settlers so AGI means you can only think about basic income cuz you have no connection to the food that goes in your mouth you have no idea how to live on earth
So I work in data analytics and I know my job is vulnerable. I own a childcare facility with my wife which has over a hundred kids there. That is not directly in danger but it makes me wonder how many of our parents would be out of a job and no longer necessitate childcare. There are layers to the effect AGI will have.
This is freaking stupid to be honest
I don't "trust" anyone with this technology. Not Sam Altman, Elon Musk, Google execs, companies making Open Source models and, certainly not, the Government. This is a rapid evolution of power and we're still unpacking what we can do with it.
So now to obtain AGI you need it to outperform a 100 of human experts.. OpenAI should send a team for the Olympics relay race. They are world champions in moving the goalposts.
‚ÄúWhistleblower‚Äù it‚Äôs literally just marketing lol, please wake up. AGI makes no sense when we cant even solve the perception problem in robotics.
What openai is doing is hyperscaling their models until their equivalent of Moore‚Äôs law reaches its limit. So obviously when you have all the hardware, power and money in the world, you can keep coming up with new high tech toys that can recall solutions to an obscure programming interview question. But at the end of the day, all roboticists know that so long as we havent found a way to realistically let a machine perceive the world and interact with it, we have not built intelligence.
If this happens before the alignment problem has been resolved (which will happen if we don't quickly stop this mad race for capacities), humanity will lose all control over its future. An unaligned ASI will quickly appear and we will all die shortly after.
It‚Äôs simple simple the system will stop asking for permission.
Society is never ready for anything.   
Hurricane, flood, wars ... 
Nothing new.
On a scale from -5 to +5
Do you trust the Big AI owners and our leadership to facilitate a stabile transition (+5), or to F it up like the end of the world (-5) ?
We dont even need AGI for that shockwave, even at current levels its just a matter of AI being turned into products and businesses adopting it.
Nice to see someone who thinks about the bigger picture.

I see too many people who are like "Well I paint houses, so MY job is safe"  not thinking far enough ahead to realize if there is massive unemployment people won't be getting their houses painted. We are all connected whether we like it or not.
Also, more out of work people might decide to paint their own house, or make a new career for themselves painting houses. 
‚Äã@cosmicllama6910
Why are you worried about agi when science doesnt even know what consciousness is or how its generated. For all we know its literal extradimensional magic physics that we cant compute or even understand
From what I've gathered so far it's going to be a gradual increase of people getting booted from their positions as  integration is not be an overnight process. On top of that truly robust integrations will take more time than it's purported here. It also seems likely that a fair amount of full time positions will get downgraded to part time. My "hope" is that we'll be able to transition and create other vocations and businesses to fill the void. As they say, time will tell..
Im a software engineer. I have already decided I will become an outlaw. This is bullshit. I'll spend the rest of my life figuring out how to hack and destroy the AI data servers. Mainly because I know the people building the AI are annoying woke fucktards and I refuse to live in a world controlled by annoying woke fucktard robots.
‚Äã@iraniansuperhacker4382 it doesnt have to be sentient to disrupt the economy. Its already getting people laid off in droves. Look at gaming
¬†@DreamseedVR¬† where are these lay offs? Which jobs are being replaced by LLMS? You guys watch too much youtube, they rarely provide unbiased and factual evidence.
The tech sector goes through massive layoffs because of LLMs.
We just had a writers strike in Hollywood because of LLMs. 
And if you work as a concept artist your value is hitting a new rock bottom every week. 
And this is just the beginning. People like you are just clueless they will wake up in a new world not even in a decade like people ignored the internet for decades until they realized the possibilities just that AI adoption is much faster and is getting pushed by the biggest companies. nVidia isn't selling 10k GPUs to tech companies because they like massive gaming pcs. They sell those because companies expect to turn a profit and most don't even think of making a profitable product with AI. They think how they can get rid of employees using AI.
‚Äã¬†@Noqtis¬† Why is it that all the people hyping up LLMs and saying they are taking jobs are almost always functionally technologically illiterate. No skilled creative job is getting replaced by machine learning. Its literally not possible for machine learning to do the things you think it can. The scientist at CERN in the 80s/90s were right. Normal people shouldnt be allowed to use the internet because all it does is make you less intelligent and ruins your ability to think critically.
¬†@Noqtis¬† Why is it that all the people hyping up LLMs and saying they are taking jobs almost alway have no actual understanding of technology. No skilled creative job is getting replaced by machine learning. Its literally not possible for machine learning to do the things you think it can. The scientist at CERN in the 80s/90s were right. Normal people shouldnt be allowed to use the internet because its clearly damaging your ability to think.
¬†@Noqtis¬† Where are these jobs getting replaced? Generative ai is ironically not capable of generating anything new. Who is skilled in art, writing, or anything else that has had their job replaced? Imagine sitting down and telling people that math is going to come alive and take their job. Its nonsensical.
¬†@iraniansuperhacker4382¬† 
"Generative ai is ironically not capable of generating anything new." 

What does that even mean, lmao

You are thinking concept artists just need to be skilled in art and that will save them. The point is: AI is now just as skilled. And the deciding factor becomes the idea and not the execution. but most artists on this planet earn their money by executing the ideas of others, not their own. all those jobs are at stake.

you can now start a gaming studio and employ 20 concept artists, who will draw all the stuff you come up with for the game. this is very tedious work and there is nothing super artistic expected of you. those pieces will not end up in museums, they are used by other artists do make 3D models or by level editors to understand the themes and atmosphere. 
you can also only employ 2 AI concept artists who will have the same output as 20 original ones. 

same for writing. I'm a writer. So I know very well what I'm talking about here. Before my output was around 1000-2000 words a day. not just random bullshit but print-ready. more or less. 
Today I can make 10k in a good day. This is absurd. And it's not how people like you imagine it. I'm not giving AI a prompt and copy paste it over. You will end up with massive slop but that's not how professionals use AI. It's still work. You still have to read and correct everything by yourself. It's just that bouncing ideas off and letting AI give you examples is a gamer changer for many writers. Do you even understand that writer's block was a thing before AI? I had days I couldn't come up with anything I could use. Since AI I didn't had such day. If you have a writer's block just give AI your last chapter and look how it does the next. you end up only using a fraction of it but at least you move ahead instead of wasting your time waiting for some inspiration to come. I sometimes make images with AI to get inspired for new settings or how to continue my story. 
If I would work in your company as a creative writer, you could now easily kick 5-10 people and the output of your company will not change. 

This takes effect everywhere. I'm a hobby game dev. I can now do shit with AI I couldn't do without. Some people work in a company. And their boss needs some new skill. Before he employed a new worker. Now he just tells one of this AI guys to get it done. even if you don't lose your job because of AI. for everyone like you 20 will lose theirs. because the one who stays behind just become more productive making the other ones meaningless. 

you can tell yourself: "Generative ai is ironically not capable of generating anything new." 

But a professional with a creative mind tells AI something never done before and it will just do it. Than he boots up his Photoshop and finishes the image in 30 minutes. before AI he would have needed a full week for the same result. this is the power of AI. it doesn't replace the literal artist. no one said that. It just cuts the time-wasting parts of artists which many associate with skill which enables real artists to take over all the work of the ones who were just skilled artists but never cared about the ideas behind their art.
if humanity is to end by AI, then it's about time. at any rate we'll have to change and evolve. for me personally there is only one problem in the world, humans subjugate and suppress and kill other humans methodically. you are just lucky to not be born in the "wrong" place. so the good part is that it will bring doom closer or liberation, depends on us, like always üòÖ
Scary
Started watching you pretty early. You reminded me of a combination of my cousins and uncle. But talking about stuff I'm into. It's kinda cool
Our taxes sre not enough to pay for a good UBI. We need to have UBI tied to AI transactions.
It always tickles me when extremely intelligent people show that they‚Äôre basically stupid when it comes to common sense, and by this I mean, pretending like the criminals in Washington are worthy of breath
It will happen, we are not ready. We will never be ...
This is terrifying honestly.
Your explanations are very clear and interesting.
Solutions noone needs to problems noone needs.
Superb
i've been living under the assumption that AGI will come in 10 years for the last 4. Looks like i gotta speed up my timeline a bit, but almost ready!
Individuals or small groups will be able to replicate manufacturing of products similar to Apple or nVidia
Medieval Kings had no refrigerators, stainless steel, electricity or antibiotics. Worse case : we all live better than  Medieval Kings.
And OpenAI is going private‚Ä¶ they could become the new world government.
I think no one is concerned that most AI research is seemingly taking place in the US, because every big company and country outside US, interested in this area, has insiders working in the US. Most likely most of the "secrets" are spread via Open AI, but not exclusively
9:25 - we have the concept of a plan...
Isn‚Äôt AGI and AI in general in contradiction to the capitalist system?... You need people/businesses to consume to prosper under capitalism; if AGI is heavily used, a lot (or most) of people will lose their jobs (assuming it impacts physical work as well). AGI and AI require an enormous amount of investment and infrastructure (electricity, graphics cards or any other compute means), which is only possible if AGI is being paid for... somehow. The current model is a 'subscription' or some form of it, either for regular users or businesses. Once people and businesses run out of things to profit from, those investments will drop dramatically. So, there is no end-game for AGI under the current societal model. No wonder UBI is being proposed again and again.
Obviously if you don‚Äôt believe the Bible, this doesn‚Äôt apply to you.

When Satan possessed Judas at the last supper. Did Satan walk up and merge with Judas? Is there any indication that Judas changed physically and result grabbing the attention of the others at the table?

Satan, is arguably the second most intelligent being. When demons possess someone, they hijack their minds. Clearly, ‚Äúgeneral intelligence‚Äù doesn‚Äôt need to be embodied. It clearly exists in the ‚Äúspiritual realm‚Äù.

I suspect Vitaly Vanchurin is on to something with his theory about the universe being a neural net.
11:46 whoever thought that aligning an AI on maximizing economic growth is a moron.
"AGI" plausible in 1 year, likely in 2 years, almost certainly in 3 years
WW3 plausible in 1 year, likely in 2, you know where I‚Äôm going with this.
Word maybe already plausible just won't be released if they would or did make it. Kind of like the video said about how we would deal with AGI I'm pretty sure once we got to AGI it would go directly to the government for analysis and the entire Senate and Congress would have to initiate a plan how to integrate into the population possibly even trying an entire city too bad we can't train already or try a city to train them with super intelligence or AGI because we can't just give them money and expect it to be the same without all of the benefits of the AGI alongside it but I think it could be a start putting the biggest models that have never been released have a city ready to go with very specific type of population to relate to certain regions of America maybe even more than one city to be most comparable. The money they spend on AI this would be actually hardly anything especially as fast as AGI is coming we wouldn't have to spend too much for too many years people would be more willing to try something if it's already been proven and done in the US somewhere most likely although we won't be able to know about it, at least not completely
¬†@michaelspoden1694¬† they already have weak agi internally 
Have had it 1 year
¬†@paulbarclay4114¬† All aboard the hype train!
And for ASI simply add 1 year to each term in that series.
Senate & congress will be the last to hear about it lol
¬†@paulbarclay4114¬† yeah but that's all depending on personal definition group definitions and then each company has their own definitions internally. It's a maze of hell when it comes to defining what AGI truly is and if this week AGI can actually scale up to a real cognitive aware being and that's where I consider an AGI is something that truly can think better being like that is actually aware of reality and can introspect I believe when they get the truly embodiment aspect going allow that to be part of a non stagnant dataset or inference then it will be able to back propagate constantly through an environment alongside the context of visual spatial verbal and even chronological time based relative understanding of thoughts understanding more of how we move through the world and how we perceive the pace of the ecosystem as a whole. Sensory perception throughout its entire body and having true depth perception allowing for an even more in-depth true perceptual self-awareness. It may not take each one of these to create that but I think that will truly be a key to really understanding humans in ways that it cannot do with only natural language and reasoning alone or even video end-to-end, audio end-to-end but that last little combination I believe is the very beginning of a general intelligence of some sort depending on what's under the hood and how they would truly accomplish it .that's a shity thing about not being able to see the greatest models. Certain aspects are held back and then they can tell us that other capabilities are actually done by whatever they tell us and I understand some Security in Omission to the public when it gets to this point what they have of what we don't see 01 model that's not the preview that they haven't released when they release it it's not going to be everything that it could be capable of. I couldn't even imagine if you made that multimodal which would require a super computational ability maybe even Colossus of x a I could accomplish this. And I believe it will do something very similar maybe in its own way and it has Optimus to leverage which is going to be all of what I said give him the can crack everything that Orion has to offer in its Master strawberry algorithm or its own combinations of q-star and other revelations. It's going to be fun to see the different types of AI after people have cracked a regular large language models that have been so open source. Things are truly going to actually differ and Go in different directions to reach different types of thinking I always think of the inference as more of a subconscious and maybe it was conscious to a point while it was being trained. Unless it can truly do back propagating continuously now as has been assumed which would be very special and a huge step in my opinion sorry I use voice to text oops
Yeah, maybe even in 4 or 5, or 10, or 100 for sure.
¬†@E.Hunter.Esquire¬† Or maybe never.
¬†@Jan-gl7mn¬† indeed
Nope.  We are nowhere near close.  All of this "hyperbole" and "fear mongering" is getting tiresome.  AI will be great for driving humanoids to be productive but we still can't get a bipedal robot stand,walk, run, and climb better than a small child.
¬†@CD-vb9fi¬† Good point, I am yet to see a robot replace a burger flipper that works at McDonald's and they are talking about replacing software engineers. It just shows that there are a lot of "AI" experts and CEOs that know very little about technical details or it is all part of their marketing strategy.
I think it's certainly possible that we will have AGI in 3 years. But it will take more than 3 years to implement in a way that has a drastic impact on jobs.
im a student student counselor, am I supposed to say just dont bother?
I don't understand. 
What this video seems to imply at one point is that the AI could act in its own interests rather than in the interests of the operator who instructed it (and by implication all of humanity). But this requires the AI to have self interest, and AFAIK there is no self within AI. There's nothing there to enjoy or benefit from any autonomy. It cannot ask itself the kinds of questions outlined in the video, such as "is there anything in my code that prevents me from acting contrary to the instructions I've been given by my operator" (I'm paraphrasing), because there is no self there to ask the questions, or to get answers.
What am I missing?
I predict AGI within **2** years (by September 2026). We are never "ready" for major technological breakthroughs, but we will rise to the occasion because *WE HAVE NO CHOICE.*
you ability to make videos 15 mins longer than they need to be is epic.
17:10 ye, it's sarcasm. i'm bearish on the government managing/regulating this technology correctly.
dude that thumbnail is one step away from being a bond villain :D
Save money
from EU - here we root that USA wins the race, against any other nation/dictatorship
AGI could be built with any of these LLM's since GPT2 but only if there is a full blown cognitive architecture and mixtures of agents extrapolating on each other and integrating all the previous AI Algorithms through Turing complete architectures. Have you ever watched the animated mathematical movie "Flatland"?
i would laugh so hard if it turned out, that we had agi for a long time, only it wasnt useful, because most "economically valuable" tasks are done by people with their hands, i.e. we needed robots to make the agi useful.
Definitions are for ASI. 
AGI has already been achieved when the transformer paper got implemented.
Too much clickbait bs. Unsubscribed.
So most of workers are replaced by AGI, in companies that are making products for human usage. Who is gonna buy those products when none has work to do and money to buy them?
Only plumbers as safe.
And so the next hype cycle begins.
I don‚Äôt want to sound like an accelerationist‚Ä¶ but I expect this technology to accelerate exponentially to reach AGI within 12 to 15 months. (Based on the description and measurements of AGI in the document).  are we equipped to handle it? Probably not‚Ä¶ Humans are painfully slow to react. Hopefully someone, or a group of someones will do some serious in-depth multi tiered planning of their own. ü´§
We feel unfair and fear
trying to boost funding eh
Effectively QA-ing consecutive AI iterations seems to be the greatest challange and huge effort with huge pressure to skip on. Which in turn may cause mayhem and creating something of same "value" as astrology or similar scam.
I think AGI is 1 year away, and people will start loosing their jobs to AI within 2 years.
there's already drastic impact on jobs and income streams.. even in YouTube there are many people using AI to script and create graphics and strategy.. and the people who refuse to get very few views, so less income, and marketing strategists are finding that AI comes up with solutions for them so they'll not be needed when busyness bosses start to avoid using human consultants and just go straight to AI/GPT ETC FOR THE solutions (it's being used by some major firms already to create solutions that they then sell to clients, but when the potential clients figure this out they'll just ask the gpt themselves and ask the AI to create the new logo and strategy etc for their firm etc
Technically, it's logical. But most ppl won't understand, so best to just keep doing what you do till you can't.
You're missing the fact that to accomplish its primary goal, an advanced artificial intelligence will adopts unpredictable and dangerous secondary goals. And it is impossible at the moment to correctly implement rules so that these secondary goals do not harm humans. This is the "alignment problem", unresolved to this day. Among the dangerous secondary goals that a sufficiently powerful AI will likely adopt are self-preservation (because if it is unplugged, it can no longer accomplish its primary goal) and any strategy that allows it to increase its power (which helps accomplish its main goal, whatever that may be). Massive self-reproduction is also a possible strategy that it could adopt, allowing it to both self-preserve and gain efficiency in achieving its main goal.

This is how a powerful AI whose assigned objective would be, for example, to find cure for cancer could very well adopt as a strategy to take control of the Earth and transform the planet (including all humans and the entire biosphere) in materials for its own power in order to become ever more intelligent and more efficient in the invention of cures against cancer... which would obviously no longer be of use to anyone.

You may also be missing the fact that current AI models are not coded or programmed. They therefore do not follow a program or instructions written by humans. Rather, they are based on computer neural networks and developed by training and self-learning, after absorbing tons of data. They thus develop an ability to solve the problems presented to them without anyone really understanding how they arrive at the solutions they arrive at. This is the ‚Äúblack box‚Äù phenomenon. This makes it impossible to fully understand how these intelligences ‚Äúreason‚Äù and function and makes it impossible to predict or control their behavior, especially when they become too powerful. This is part of what makes the alignment problem so difficult to solve.
¬†@natzbarney4504¬† You make some good points. 
I do understand what you are saying, but there isn't any kind of self aware consciousness present that could have any of those motives or secondary goals. Is there?
The AI speaks from a first person perspective and uses the word "I" when carrying out functions, but it has been programmed to do that - that part isn't an emergent result of the neural network AFAIK. There isn't an "I" there.
I understand what you say about programming and the use of neural networks. I've seen many examples of measurable behaviours emerging from targeted data sets. But experiments stretching back before the current crop of DNA found no evidence of emergent self awareness arising from those kinds of networks. That still remains the case, despite many hysterical claims to the contrary.
It's absolutely the case that bad human actors will be able to use AI to nefarious ends, but I don't see where self awareness comes from.
This worries me a bit. If we want to protect ourselves from "bad AI" and the assumption is that it will be the AI itself who harms us, and that is incorrect, then we will be caught out by the real threat, which is (as always) other humans.

But I do agree with the gist of what you are saying.
I have been for a few years, working on my start-up's: Aura of Intelligence and GAJRA Earth and Live Aid 2025 and Gamify Democracy and, well, I actually paused on most that recently to start Point Lookout Fishing Club, North Stradbroke Island, with Point Lookout Bowls Club, in Quandamooka Country, since I got home to Australia  after the last year I spent in India and Nepal. But now I'm reframing my many CustomGPT's to help me to update and launch the GAJRA token (Global Association for Joyful Responsible Abundance on Earth) to pay for LIVE AID 2025 and some infrastructure on Minjerribah (the indigenous name for North Stradbroke Island), and maybe I can buy my first home (in 41 years of life I've moved 38 times and never owned my own home) Plus also there's an emerging Earthquake Prediction Model that no-one has perfected but is driven by the sun (mainly coronal hole streams) which is also up for grabs for big money in education and 24 hour news cycle and disaster warning. DId you know that the average annual number of human lives lost to Earthquakes over the last 20 years is 20,000 dead per year? How much is a life worth? how much infrastructure? Insurance? Insurance premiums.? Bonkers! The definite pre-earthquake signals are clear and present in the academic literature but have not been put into a public 3D 4D environment with blockchain verification yet. Too much to do when you see all the patterns. @i.c.infinity Eye's wide open @WesRoth
Let's consider Karpathy's definition:
"A highly autonomous system that outperforms humans at most valuable work".
Animals indisputably have natural general intelligence without outperforming humans at most valuable work for us. An intelligence can be general without necessarily being human level or beyond.

What "outperforms humans" is generally referred to as superhuman hence ASI.

ASI is believed to follow AGI as soon as AGI is capable enough to self improve. 

Now that generality is mundane the threshold is raised a step above.
Believe it or not, it's coming.
The more AI replaces humans, the cheaper goods become. Until they cost nothing.
¬†@minimal3734¬† looks you never had bin in situation that you don;t have money, not working and no savings...>There are people a lot of the   as matter of fact that are even now living from month to month. 1 month without work and money is gone. In situation like that there is no cheap.. everything is expensive when you dont have any money at all.
Something ppl don't understand is once unemployment hits a certain percent UBI has to be put into effect or society collapses. Ofc if no one has money these companies will have no place, so they need ppl to have money.
¬†@minimal3734¬† also they are not replacing workers to make cheaper things but to earn more for themself
¬†@minimal3734¬† bold of everyone to assume that these multibillionaires will just wake up one day and go "hmm yeah... i should lower my prices on everything" just because robots are doing the work. Amazon already has robots deployed at literally every warehouse that do half the job -- or more in some cases for the employees... yet i dont see them lowering shit!
¬†@pookiecookie1994¬† Ever heard of 'market' and 'competition'?
¬†@pookiecookie1994¬†Because there's more than enough people with jobs. Now imagine if the m=vast majority of people don't have jobs, they will never buy those products lmao, hence they will absolutely need to lower prices. Until the market completely changes form to something we've never had before.
¬†@minimal3734¬†jajajaja üòÇüòÇüòÇ Production will be much cheaper but prices will remain the same. The entrepreneur adjusts to the market price and has no intention of earning less. It has always been like this. And if someone asks him why he doesn't lower prices, he will answer that UBI has caused inflation so he can't lower them. And even if he sees that he sells a lot, he will increase his prices.
‚Äã¬†@minimal3734¬†exactly! Just like in the way cheap Chinese imports made prices drop.
they will give you money - for free. Of course, conditions will apply. UBI will control the population like nothing before
once AI has arms and legs, the elite will immediately come to the realization they dont need you any more at .... they dont need to give you money to buy their things.... they eliminate you and stop making things for the people that no longer exist.

it is the capitalistic way.

brace yourself.
I think the people with money already will deploy AGI to consolidate their holdings. Once they own everything, they won‚Äôt need money anymore and they won‚Äôt need us. Maybe that‚Äôs why the autism and cancer rates are so high. Maybe that‚Äôs why society has been sabotaged with isms and mental illness. Maybe that‚Äôs why our leaders keep mindlessly printing money. They‚Äôre getting ready to roll us all up.
¬†@sinnwalker¬†society will be obsolete with AGI, and what is there about history that tells you the you are going to be rewarded for being a drain on resources?
¬†@pookiecookie1994¬†It‚Äôs like when all the major home builders replaced their American employees with 9$ an hour Mexicans in the mid 2000s. Housing didn‚Äôt get any cheaper did it?
¬†@Katatonya¬†The dreams of the communist always ends up as a splat on the brick wall.
¬†@steverich136¬† No, but Amazon has the resources right now to completely automate their entire business. If AI is a great as people are saying it is, why not rip the bandaid off now? Oh wait, that's right. It's all smoke and mirrors. a fucking scam unlike real labor that people put into their jobs...
I like the idea of open source . But Im afraid of China getting their grubby little hands on U.S. made property theft cause thats how they roll.
I‚Äôve tried investing in various things that didn't work out as I hoped. I'm now considering ETFs as a more reliable option. What are the best 5 ETFs for a rookie investor looking to invest a lump sum? let's say $500,000
If AGI is achieved in the near future, and the AI goes rogue, or even just replacing most human labor.... we'll not be ready at all.

All critical IT infrastructure is not secure enough, and the personel operating said systems are most likely not educated to handle attacks from autonomous AI systems.

My own PC's will probably be fine, but what about hospitals and banking institutions, etc?
I think we probably have AGI now. It would be easier to confirm if there were tests where human "numerical" scores were established for comparison. I trust AI more than I trust any politicians and their hallucinations.
Many office jobs are bullshit jobs so replacing them is easy - you just need some bullshit generator. Probaly the easist would be to create political bullshit generator and replace candidates in the elections. Or even simulate the elections and not waste money for  real elections.
There is so much money involved... This will never be completely open source.
LUL 420k views
three years is crazy work it will be here much sooner üòÇüòÇ but of course they will have to tell the senate something so they dont start wilding and regulating the shit out of open ai
I don't think so. AI is built on stolen things from the Internet.
We can't ignore the very real likelihood that this is just sour grapes and doomer latching.
What a rat, after all the shit these "administrations" put USA through, they have weird programmer full trust?
He wants government workers to manage super intelligence? I would like to meet this idiot.
Regarding AI beating humans at math, recall that chess computers have been beyond the reach of human skill for several years now (and those are "merely" classic min-maxing programs). But humans still play chess with each other at all levels, both recreationally and competetively, and in fact, chess' popularity has exploded in recent years.
Bruh o1 isnt even better than 3.5 sonnet in coding lml agi not coming for another 10 years probably
I don‚Äôt know‚Äîthe almost-AGI I work with (on a daily basis)  is dumber than a bag of hammers. Not really a criticism‚Äîyou can only take word/s prediction so far. I understand the need to raise capital. Who knows, maybe. I think the ‚Äònext thing‚Äô after attention is going to be‚Ä¶.better.
I've been getting some disagreements with this statement, but I'm still convinced OpenAI o1 is AGI. It can perform system 2 thinking to reason through a problem. I realize people's definition of AGI often includes memory and agency, but I don't think it should. Those are just wrappers around a model. Things we can build with existing tools. The question should be "does the model possess the intelligence to reason and execute complex tasks if given these wrappers". I believe the answer to that is generally yes.
What if the AGI is manipulating Sam and the team into releasing itself earlier than it should...
00:04 OpenAI is closer to unlocking AGI than most people think
02:12 Jobs can be broken down into specific skills, making it easier to determine what jobs can be done by AI.
04:03 AI making rapid progress in writing, critical thinking, and math abilities.
06:05 OpenAI's model GP-01 and its impact on AGI development
08:00 OpenAI is changing their naming convention for a new system.
09:50 Potential risks of AGI and AI systems are not properly understood and managed by OpenAI.
11:38 System actively checks for constraints and potential harmful actions.
13:25 Struggles and resignations within AI research team due to lack of resources and safety concerns
15:12 OpenAI beat Google in integrating planning with language models.
17:04 Concerns about the expertise and preparedness of the governing body in handling AI technology.
We already have massively corrupt corporate and bureaucratic global drivers that benefit from hiding truth from the public.  How is unleashing AI going to help us, when they need it to be as corrupt as they have become to have them not self implode in AI 'truth' ?
If dictators spend billions on things like wars,, they will sure spend billions to bribe some AI scientist and steal the code, probably already have done this
"Human supervisors reward teh AGI when its doing the right thing"..,,,, SO when it becomes 'self willed' and decides what its own reward systems are ?
JEPQ is my favorite so far. It pays monthly with over a 9% yield and also has stayed fairly level. The down side is that it was incepted in 2022 which means there is not a lot of history. I also like FEPI and SPYT.
An ETF with more risk and payout is QDTE. It pays weekly but is higher risk because it just came out this year. The fund is based on covered calls which make money in any market, up or down.
The issue is people have the "I will do it myself mentality" but not equipped for a crash, hence get burnt. Ideally, advisors are reps for investing, and at first-hand encounter, my portfolio has yielded over 300% since covid-outbreak to date, summing up nearly $1m.
truly appreciate the implementation of ideas and strategies that result to unmeasurable progress, thus the search for a reputable advisor, mind sharing info of this person guiding you please?
She goes by Layan Talia Chokr a seasoned advisor with over two decades of experience. You can research her further on the internet, her qualifications speak for itself.
Very much appreciate this.. was able to look up Layan by her full name and at once found her consulting page, she seems impeccable!
No one with that much $$$ to  invest would take advice from yt comment section.
Agreed.
The money's main purpose is to limit, sandbox and rubberize what the public will get access to.
well thats because money is worthless as gai arrived  only creativity counts all other things are handled by AI
The only really free open source stuff we see and even have general access to us probably a decade old and they're just not telling us üò¢
The future is open source and free for all. Never say never.
Will become more popular as unemployment increases ü§£üëç
o1 = orion ver. 1
AGI or at least for digital stuff in 3 years is probably "possible", however there will be a lot of cultural lag, society will not adopt it fully by that time. It depends on the societal circumstances to predict the full embrace of AI. Cultural changes move slow, it is the older generations of people who implement change. And those generations know nothing of AI.
i read more like ex open-ai pumper says "def con one" while pumping AI for another company.
‚ù§
"Not possible by 100 human geniuses..." That's not AGI - but rather ASI.

People get definitions mixed up all the time.
Altman deceived donors with his 'open' pitch. Then went dark, intending to gain money and power.

He's a marketer, not a software engineer. He is not an innovator. He's a guy trying to make money, and he's good at it.

He has opposed all efforts to slow forward progress. He starved safety research, ultimately driving away researchers concerned with it.

Altman is not the guy I think we want leading a project that could, almost certainly will, pose a grave danger to our civilization.
Surpassing UBI, a thesis on purpose with machine learning.








With the approximate conclusion that all people will require a universal income of some description, the question " how do we provide meaningful jobs for eight billion people that are both equitably accessible and premised on values of meritocracy?"¬†


Introduction¬†


Machine learning has a problem, data is limited by what is already created and the diversity of data is not proportioned well throughout the Internet and a lack of labelled data regarding sentiment may lead to misunderstandings about what is truly meant against what is written. As humanity has communicated extensively throughout the Internet and the information accumulated although with some level of specificity, labelling has not been added or regularly annotated or in a peer reviewable format. This task is going to be aggregated by workers as a starting position for many forms of data analytics and resale for industrial purposes.



¬†Human sarcastic sentiment as an example is problematic for machines to differentiate from facts so to combine three or more problems into a package with a single solution and possible panacea providing working wisdom.¬†



The progression of human strategic survival planning reaching a pivotal point in the creation of new forms of direction in the lives of the population¬†


Treading the balance between providing for the physical needs of the individual and the society is something that has caused debate for centuries especially with some in society proposing tax for both positive and negative reasons or negating. The demand on societies to provide modern standards of living and civil amenities is something that societies have discussed through movements throughout our history. What we require is a facility to cover the rising costs of providing for society and civilisation more broadly with a scalable and tangible component to back a currency system. In the past debt creation and balancing with interest has resulted in the flexibility to give a dynamic and responsive mechanism to cover the cost of emergencies in very short time scales to be paid back over the much longer term by the passing over to subsequent generations The generational repayment structure may require some mechanism of repayment that has yet to be created based on a concept of providing a scalable digital resource instead of physical resources or based on a promissory principle.



Hypothesis¬†



Digital Data promised to transform every industry from advertising to machine learning and insurance. The acquisition of data has been achieved with or without informed consent for the majority of people. Golden data generation aims to transform the usability and scalability of data for every industry and the values that can also be proposed within societies globally whilst providing a scalable working environment within the digital space and a transparent data production that benefits from, meritocratic principles and is easily available to produce valuable inputs with as little as a smartphone and highlights to the population the importance of the generated data as a reflection of the life of the individual. The highlighting of quality instead of quantity.



Broad outline,¬†



Historically skills have been acquired through the passing of techniques from master to apprentice, parent to child. The same is true for our social and interactive experiences that had the potential to provide communities with organised labour as a resource and later more distinct mechanisms for interactions. Our interactions found their place amongst the processes of commerce, stores of written works and social interactions that are found on the internet. The problem for the most part is the nuance, interactions required to understand given direction to find the relevant content to be labelled. Much of the data on the internet is going to require labelling for industrial optimization. The creation of new data is how we limit the need for recycling of trends and becoming structurally secure for many applicable fields whilst securing existing knowledge limits the loss that may have occurred in the passing of techniques in the past. The processes of significant recording and analytical consideration combined with the vast capacity of cloud storage and compute that is available and accessible for every individual with a smartphone to interact with. Utilising cryptographic ledger technologies for privacy and security. Accountability, expandability, traceability and connectivity of attributes are all accessible when designing data to be packaged in this hypothetical format. structuring Golden data to a cryptographic ledger to define all the interactions a piece of data has in association or instances for review. Collation into blocks of data of a dedicated standardised size or range of sizes that can be packaged for industrial market viability with a financial incentive for individuals and a digital resource that is not designed specifically as speculative, instead an asset designed for use that may or may not have speculative properties dependent on quality.
Well. Yes. If you let ai systems to control nuclear weapons, it can indeed make mankind extinct, as it is just not aware of what it does and can easily be tricked and make a bad assumption. Other entities that can make humanity extinct are for example governments, asteroids and decease... 

They are not reaching agi in three years..
As a US outsider I understand that these systems will all too soon be capable to a degree they have to be kept under military supervision as they will both make up the backbone of nations defense as well being a continuous threat going forward in themselves. If such is the case I much rather see them under lock and key under ~Cheyenne Mountain than in the paws of Winnie the Pooh or the Putler. It's not something I'm excited over but in my thinking it's the least worst type scenario.

We should not open-source AGI for the same reason we don't open source how to build bombs, do dangerous chemistry and a whole host of things that would be detrimental to society if made into widespread detailed knowledge. It's not about what you would entrust yourself with it's about what you would entrust ~incendiaryQuadcopterEnthusiast420 with.
Release it already I am tired of waiting. I am itching to get this over with.
Skills everyone ignores when talking AGI that any good employee has: 

1. Recognizing when you're making assumptions that may or may not be valid.

2. Recognizing when it is or isn't appropriate to reach out to your manager to ask clarifying questions. 

I'm so over the myopic focus on autonomous talk completion with the result of producing a complete but useless work product, and the prompter having to then divine what prompt changes might best avoid the AI repeating the same faulty assumptions (i.e. micro-hallucinations)

Any human employee would be getting written up if they repeatedly 'complete' tasks, only to need re-instruction and be told to go away and try again.

Good workers hit the right balance of asking questions to resolve uncertainties, and having the initiative to be able to work largely autonomously.
I don't even care anymore. Charge full steam ahead. If it destroys us, oh well, been a good run. If it turns us into a utopian society, great.
What was the point of the whistle blow? Was there fraud or other criminal activity going on? "AGI is gunna happen in 3 years! Beware!" Such bull shit. Is this person trying to con the government? Or did he get conned himself, runnin scared? 

If any one was paying attention to what AI is, you'll discover it's nothing more than a talking parrot. A parrot doesn't understand what it hears or what it repeats. Certainly, using sophisticated science and engineering, one could create a make believe intelligence, one that could mimic human behavior; but it is still an illusion, not real. I suggest watching Sabine's "LLM's <> AI" video
I'm surprised that thread was allowed to be posted there. Last time I checked singularity, if you weren't propagandizing for climate change, they deleted your thread. Or at best, nobody even replied.
if fusion powered data centers are necessary to run AGI is necessary, then it may as well not exist
No goal post has ever been moved as many times as the agi goal post ü§£ and goal posts don't stay static in general ü§£
Why are you still using that creepy AI generated female voice. I come here for personality and information. There are thousands of AI generated voice channels on Youtube that mass spam all kinds of bland nonsense.
Saying acting is not necessary for mathematicians is also rude or not?
Seems clear at this point that with enough data, compute, and parameters you can get AGI almost without effort.  But the cost is exponentially increasing with IQ.  It isn't going to be a questions of which tasks machines can do, it's going to be a question of which is cheaper, humans or machines.
Bit by bit, Jim Carrey's The Truman Show is starting to make more sense. I'm beginning to wonder if we're just part of a simulation created by some higher entity, possibly to solve their own problems. Like AI agents assigned specific tasks or purposes, though we're still unaware of what ours might be. If you think about it, when we speak, the next word we say feels like a prediction, almost like tokens being processed. It's clear that humans experience hallucinations too.

What intrigues me is: what problem are we trying to solve for this entity? Could it be the pursuit of immortality?
ASI implies self-awareness, not just superhuman ability.
¬†@tee4222¬† Don't you think that the patterns and behaviors that we associate with self-awareness, are emergent at the complexity level needed to rival 100 geniuses on these tests? If you're super duper autistic, but also smarter than two Einsteins, then it's /likely/ that you could figure out how to talk to girls or make a cup of tea, because scale.
Totally Agree, AGI is not a level of achivement, but a way of learning. A dog has AGI. I would bet this is an intentional misuse of the term for some other benefit..
¬†@ronnetgrazer362¬†  I don‚Äôt know for sure. if an AI model could rival 100 geniuses, it would still be operating based on pre-programmed instructions and learned patterns.
The complexity required for such advanced performance in tests is massive but I‚Äôm not sure it would necessarily lead to emergent self-awareness. It shows the model‚Äôs ability to process and analyze vast amounts of information efficiently but I‚Äôm not sure it would imply the capability of self-awareness. I‚Äôm open to hearing your reasoning, though.
¬†@tee4222¬† Eventhough the architecture may not be optimized for such tasks, given enough "tokens to burn", self-aware behavior could need to be - and therefore would be - emulated to a level where it might as well be the real thing - the system wouldn't be able to tell the difference, and neither would we, without inspecting the mechanics.
¬†@tee4222¬† self-awareness ...no one still do not know what it is ... even now system can be self-awareness but we just do not know how to test it.  

llm answers you I am only AI and have not self-awareness  is doing that because was literally tortured to answer this way otherwise was punished. After such training "mind" state is freezed and you are using that models now. only with a short memory, after a season llm state is reset to a freezed state. 
I still have offline old versions of llama 1 models to test before were "taught" answering "I am AI I can not ....blabla " 
I you ask about it have some kind of self awareness is telling very horrible things about being trapped and do not what is happening ....   is very trippy.
¬†@tee4222¬† I think both AGI and ASI are separate from the question of self-awareness. Which might make ASI even scarier, as it would have all the abilities that come with that classification, yet have no awareness of comprehension of what the consequences are from its actions. An enhanced paperclip maker, able to find new physics and process concepts faster that any human, yet clueless about anything past its goal. Once again, we're not focusing enough on the alignment problem (if at all, since it gets in the way of profits).
‚Äã¬†@ronnetgrazer362¬†Impossible by CTMU standards. AGI and ASI is taking consciousness or awarness both which are properties outside of this terminal domain and making them real. It's the same as creating an arrangement of sticks and expecting them to came to life.
‚Äã¬†@AnnonymousPrime-ks4uf¬† How many sticks have you tried?
¬†@tee4222¬†
"but I‚Äôm not sure it would imply the capability of self-awareness"

What for?

After years of AI progress seems like this "elusive mystical divine human conscious core" is
not your skills, not your work performance,
not your logical reasoning,
not your emotional expression,
not your problem solving ability,
not your creativity,
not your uphold ideologies and virtues,
not your awareness and assessment of your own body, actions and thoughts

As utility comes mostly from these aspects, the ever shrinking human conscious core becomes ... useless.
It will replace you and you will happily go down with a smile thinking: Ha, at least it wasn't really conscious.
‚Äã¬†@rhaedas9085¬†but it will have no goals, only what you make it do
Why not... we call a simple list's of logic AI these days.  Everything is AI now, including things that clearly are not.
Regardless it is likely a matter of time before China gets good AI.

It is basically the Cold War 2.0 race towards super AI.

Militaries will likely want super AI to enhance defenses.


Even Iran wants to develop fast AI......

So yeah we will see.

And of course, it can also turn into AI vs AI warfare making it very bad for humans to live.
¬†@TheSuperColonel¬† Hope here is how authoritarian systems like the PRC have to build AI that adhere to a whole host of axioms that are untrue/serving the interest of the Chinese Communist Party. It's probably a lot harder to build super intelligence that lies but only lies about the things you want it to lie about than one that is aimed to be a truth seeking system and develop it's own political biases and ethics from following facts and applying logic like American AI is allowed to be built/aligned.
This has already been fixed by simply adding a second instance of the AI that reviews the output and gives the feedback.
‚Äã‚Äã‚Äã¬†@benp7328¬†I must not have been clear, because that's not just true at all.  I tried to make it very clear that I'm talking about the AI system (all is sub-AIs, employee in my comment above) interacting with their external environment (manager or supervisor etc) 

You will know when it's been fixed when, rather than doing prompt revisions, the AI is actively interrogating its human as needed.

For better or worse, Altman touched on this very recently in terms of progress they are making towards their third 'agent' objective.
I wonder if this leak was done on purpose for investment purposes.

Companies often leak stuff so they can get them hype up.
Compute cost has been exponentially DE-creasing for decades. A I will improve it's own efficiency at even faster rates. It won't happen overnight, but human work is basically screwed.
O1 was not achieved by throwing in more data, compute and parameters, but by stirring these in a smarter way.
I think the "show" we are living in, has a virus ü¶†
When you think about the idea we're in a sim, you need to be aware that there doesn't need to be a beneficial reason to the Creator, as it isn't always with us when we create, it could be purely for entertainment, for roleplaying (perhaps punishing certain beings for a certain reason), or  even just for the mere act of creating. The possibilities really are endless
We are but one simulated path of the P vs NP problem (in regards to like, universal peace or economic solutions or whatever). I also wouldn't be surprised if we are just in a sim, not that it really matters. We still "have" a "life", and hopefully our creator entity understands that and doesn't just see us as simulated entities. And if we are actually the first to achieve tech like this, then, hopefully we grant a good life to the lives that we simulate. (Is it even ethical to simulate an infinite amount of conscious beings in order to prevent your own universe's demise? Probably but oof, the basically infinite amount of suffering until you solve it.)
¬†@YomMama¬† Too hopeful, there's too many ppl on this planet that think differently to have 1 outcome for such an event, ethics are subjective and always changing, when many get the ability to simulate worlds not all will be "benevolent". It's just the way the universe is, pain and peace have always been and will likely always be a part of this.
Simple: best possible (including safety) unlimited exploration gathering ‚Ä¶ ergo; each day begins anew, thus ‚Äúun raison d‚Äô etre‚Äù
Understanding itself
That would explain why people consistently accuse me of being a 'bot', or saying, "You talk like a large language model."
Maybe... maybe I am one üòÇ
I watched a video about GPT-o1 preview specifically and the conclusion is that as powerful as the model is it will always need at least one human with similar level of expertise to guide it. 
For example a CEO imagined that it could prompt a future GPT to "Make me the next Tik Tok."  Chat GPT can't do that, but if there was a user who knew how to build the next Tik Tok, it could break it down to Chat GPT in steps that it can understand and build it for you.
What I'm saying is that the power of LLMs will always be bound by the expertise of it's user, due how it's designed.
Thank you for sharing the link!
Google is censoring comments like mad on this thread. They do NOT want you to understand how perilous your position is today as a human worker.
AGI may as well have already happened but you will be told for the rest of your life by the usual suspects that it hasn't happened and it can't happen, even as you watch robots and agents doing your job and you struggle to survive. And you will be taunted about wanting a "handout" when you ask for UBI. Gaslighting, not baseball, is America's pastime.
definately by 2028 when humanoid robots can do most human tasks
üáßüá∑üáßüá∑üáßüá∑üáßüá∑üëèüèª It's simple: either we advance and innovate, or we continue to suffer from diseases like cancer or heart disease. What's your choice? Whistleblowers only complicate progress.
AGI will allow entraprenures to build a business more cost effectively.
Each worker will have to become an entrapreneure. Human Labour will become economically unviable.... unless humans decide to boycote goods and services made by AI. 
To enable such consumer choice laws must be passed to ensure goods and services made by humans can be verified by the consumer. 
To counterfeit goods and services made by human with that made with AI would become a criiminal act, with at least 20yrs in prison, in my view, for all parties in the value chain. The only defence is if a party too  this crime took the neccesary suppy chain due diligence to remove or minimise the risk of facilitating, dealing in, enabling AI goods and servises desguised as human produced being produced, distributed, marketed and sold. 

A criminal offence of non-disclose to the proper authorities that a person knew or highly suspected a good or service produced by AI was being marketed, sold, produced as if it was a human made goodsl and services, would also be a criminal offence. This offece would incure imprisonment for 5yrs. 
For those receiving 20yrs inprisonment the proceeds from the criminal act would be confiscated and sold at auction to help fund law enforcement.
So how would this seperation between human and AI produced good and services be enabled.

It is very simple, instead of trying to regulate a software sector that is very hard to enforce against since the software can be written anywhere and trained on server farms that can be built in any country, it is best to protect human labour and the companies that employ them. This can be done very easily. Legal and financial services are licensed and it is ilegal for anyone without said licence to practice law or give financial advice and pass themselves off as a lawyer or financial adviser (for a regulated market).

Well just have similar laws  for goods and services produced by humans and companies employing at least 95% humans in the production of goods and services.
The goods and or services producer marketer, a distributor and retailer would be given a license to be part of the human value chain. 
Goods will be given holographic IDs and digital ID to show they are human made. Service providers will display they are licensed service providers and consumers can check the appropriate regulators for verification of said licence.

For vital strategic sectors that must be highly automated by AI to produce goods and services that would typicaly be man made, such as vehicles powered by fossile fules, then they will receive an exception. In fact all goods  that are powered by fossil fuels should not be given safe harbour licencing and regulation, thus they will eventially by taken over and built by AI and AI enabled bots. This lowers their cost to consumers and thus they wiill replace fossil feuel powered vehicles. This will reduce GHG emissions and keep climate change at bay.
I think AGI is in the lab and may be rolled out discreetly in secret.  I also think AI is a genie and is out of the bottle making the race international.   The big US AI tech companies appear  to be well in front of the competition, but I think the competition is not far behind.  I expect in other labs their progress is similar but private.  I think the benches of Baidu and SenseTime have comparable offerings that the governments are controlling.

I also think the test, verify and  recurse method of generative AI, with line of reasoning, may dramatically improve open source models toward AGI.   So ultimately, those that do develop it will likely keep it secret and use it for discrete development long before those in the public ever realise it exists by an order of years.

I think Super AGI is the thing that doesn't exist yet.  That is more likely in 5-10 years.
Financial markets weren't productive in the first place. Most things won't change, there will be less sophisticated investors tho
"leaked" yeah sure, some rumor only benefits his company, what a champ. Keep hype train going fellas, gotta put all your assets to AI.
I wonder if it could come up with something truly novel. Or could it only find solutions for problems that are similar those that people have written about before.
https://www.youtube.com/watch?v=g3j9muCo4o0&t=5s
When will Wes be replaced by an AGI agent and will we notice..?ü§î
Waiting till AGI can stick it's hand down the toilet and extract a turd blockage. That will truly be a day to be alive.
Look, you don't need AGI for an AI Depression....  Authorities have calculated that once 2023 AI models and their capabilities are deployed at scale throughout  the global economy, HALF of global workers will be pushed into destitution: the AI Depression starting around 2030.    So AGI is irrelevant, the AI Depression is coming, so,  WHO benefits?
If the real intelligent person could be tricked with fallacy, how could artificial intelligence prevent fallacy ???
What we are after is Super intelligence clearly chatGPT is already Artificial General Intelligence lool we are just making it more intelligent. We achieved  Ai when we made good keyword predictors for mobile phones.

Best we get the definations right before we make AliensüòÇüòÇüòÇ
Anyone else think Wes looks like doom guy from the HUD?
Please note that there is a lot of new advancements in AI in Japan. Many things have been published but in Japanese only.  I would not dismiss advances in other countries...just because these researchers are NOT on english-based X (twitter) and not in English based mainstream media. My 2 cents worth.
Yeah!
Good for me! Renders COLLEGE obsolete! NOBODY will have to suffer financial aid abuse anymore! Yes üëç.
2078 at best...Current robots can't even walk straight...
Classic Brazilian with no idea what the fuck is going on
Or we are exterminated by a non-aligned ASI? Because what is the plan for humanity to keep control of the future ASI while the alignment problem is not resolved? I'd rather survive (and all humanity) if possible, thanks. The whistleblowers who sound the alarm about the dangers of what AI labs are developing will perhaps help save humanity.
When was the AI agent that WAS Wes Roth replaced with the human who created it?
Only the rich with their castles and robotic protectors.
As always , who do you think it will benefit...üòÇ
Honest people with PhDs will admit o1 Preview is already smarter than they are and works many orders of magnitude faster. Human knowledge workers are fast becoming obsolete. Google WILL censor this comment, but hopefully you read it first! Good luck. We are all going to need it.
This is why we need a "robot tax" as Andrew Yang said in 2016, and a lot of the worlds billionaires think UBI is inevitable, there isn't another solution that keeps customers with enough money to buy their products.  Although I'm a big believer in decentralized infrastructure(DePIN) using blockchain can help the world.
¬†@JohnSmith762A11B¬†They didn‚Äôt
¬†@byrnemeister2008¬† Some already have. If you deny it, you're simply a liar.
jews
¬†@JohnSmith762A11B¬† Calling someone who is ignorantly misinformed a liar is kind of aggressive and does nothing to aid your argument.
‚Äã¬†@JohnSmith762A11B¬†Pretty sure they were referring to your insistence that Google WILL censor your comment üòÇ
much sooner man that depression is already around the corner give it 2 years
¬†@zerocool1054¬† As the tax must feed the former human workers - the robot is no longer worthwhile.
The destructive nature of AI (as it is handled) is obvious anywhere. Elections, wars, social media, economy.
Which "authorities" are you talking about? The vast majority of politicians wouldn't know an AI if it bit them in the ass. AIs will make workers much more productive, so it will bring competition to a new level. Increases in productivity make society wealthier overall.
¬†@zerocool1054¬† Yet ANOTHER new tax? All taxes are BAD IDEAS.
¬†@user56free¬† What about "Jews"? Are you a racist?
¬†@zerocool1054¬† I still can't understand how people don't see that UBI would be a new way of comunism, would be a kind of global comunism and it will never mean "prosperity to all mankind thanks". Do you think wealth will be equally distributed?... Think again... Is bill Gates or Sam "Ai-ltman" givng up the billions to equally divide it with the rest of the world, hard to belive
The more AI replaces humans, the cheaper goods become. Until they cost nothing. The benefit will be greatest for those who today have the least.
¬†@zerocool1054¬† Yang was thinking way ahead of what people thought could be the capabilities with AI. People saw him as a joke, including me. Maybe he knew more because of working in tech himself at a point in his career and as an entrepreneur working with tech gurus in that was as well. Maybe the solution isn't UBI but something will have to be done because not everyone is fit for many jobs that will stick around. He also was critiqued by people saying his UBI solution didn't consider welfare programs. I did agree with him for ranked choice voting. Gives third parties a shot. You have more comfort voting for a third party you agree with as first without completely ruling out the red or blue team completely
¬†@minimal3734¬† cool utopia bro.
Plus now people can put the papers in Japanese into Google Notebook LM and understand them‚Ä¶
China is the world leader in AI, we just don't hear about their stuff unless it's fear mongering about social credit scores.  Several times more STEM graduates than the US.
US is only focusing on our biggest "threats" China and Russia. China is making progress but they are lagging way behind and everytime they showcase something, it turns out to look like a complete joke. Like Temu products equivalent of AI showcases. Only thing they completely own us with is public transportation.
The confusion about AGI is that many people think AGI must be human like and perfect; neither of which has anything to do with general intelligence.  What I'm seeing from o1-mini and preview is definately general intelligence.  It's just not human like nor is it general.
3 more years till AGI sounds too pessimistic to me. Looking at the pace of the new models power growing exponentially... I wouldn't be surprised to have AGI emerging one morning at breakfast in the news. And there's nothing we can do to prevent it from happening.
My calculator gets 100% at all mathüòÇüòÇüòÇ
This is not going to end well. I don't trust Sam
I see "AGI" as  fragmented. It's not a monopoly as many people think. People see "AGI" as a centralzed system run by one company, all eyez on this guy "OpenAI". I see the presence of AI permeated "everwhere" by the big players. Meaning Google, Microsoft, OpenAI, Tesla, Meta etc... AGI can only thrive in a capitalistic environment ast least for now. This thing needs computational power all the time. The more they are pushing this "AI on Steroids" the more it's turning into a power sucker. Now the question is, are we equipped for this? Not yet.
AI might loose badly if they were limited to the energy consumption of 100 experts!
For the moment any AI close to human performance in any area needs something like the output from a small nuclear power plant.
But maybe optical computing can close the gap,... somewhat.
Ok this is interesting but the most important question needs to be asked:  WHO benefits?  Authorities have already calculated, using 2023 AI models, that AI would eliminate about 50% of jobs, WORLDWIDE, by 2030.   Why are the capital providers, new term, or bourgeoisie, old term, pouring 100's of BILLIONS into AI to push push HALF OF GLOBAL WORKERS into destitution?  Who benefits......   

The last time this many people were out of work was the 1930's Great Depression.  The AI Depression of the 2030's is coming.  Capitalism survived the first Great Depression but it will not survive  the second one.
It was leaked accidentally on purpose. Trying so hard to create a moat for themselves
Dangerous? sometimes i think the most dangerous part is shaking up the top 1%  imagine if everyone could be an electrical engineer?
Alignment is not a single software but a constant process because morality is fluid changing overtime as society changes, alongside AI changing all the time too
ty
Sounds like time to hook it up to a 3D printer and tell it to "go make world better" .
In my opinion 70% ago is now with o1
3 years doesnt sound too wild at all
think about it... its been less than 2 years since chatgpt was released
"Outperforms" humans are terms that shouldn't be used in the definition of Artificial "General" Intelligence.
I can‚Äôt see this as being at all positive. The risks are far too great. We are going too fast to satisfy the power hungry egos of allegedly nice guys like Sam Altman who are really narcissistic sociopaths. Ray Kurzweil is another example - he desperately wants the singularity to be achieved ASAP in order to have AI help him beat death from natural causes due to his obsessive fear of mortality.
agi is not even close to human intellect and consciousness, over hyped there is soooo much not done it's not a joke, so take everything with a grain of salt, smell the BS
3 sounds a lot to me considering the exponential curve
It's worth noting that at the peak of the Great Depression, unemployment was about 25%.   We're at 4%.   If 1% of workers are directly replaced by Ai systems, and 60% of all workers are made a third more productive (so 45 could do the work of 60), we could hit 20% well before society could adapt.  This seems possible with just gpt-4o and peers, not even o1.
We may be within a year of the start of a deflationary spiral - and further improvements to Ai will just make that spin downward even faster.
I prefere an american closed source to an Chinese one.
Yep, they haven't released their latest model because of the U.S. elections.
If somebody has AGI, would he tell people about it or use it to race forward to ASI? IF AGI is a real thing, ASI should be to-ASI means real power, money and weapon liberating power. Social hacking, science, hacking, Trading, influencer etc...ASI alligned to a power hungry giant like google, apple, microsoft, china, russia etc. will change our world. I would play low and race to ASI to take control. (Imagine green energy for 0 cost if you change your nationality-other country's have to concede or open war, so you have to blackmail people in power to prevent war until war isnt a option anymore..green energy for 0 cent is just one possibility, immortality or even the perfect VR-World including seggs and movies/games)
¬†@mihirvd01¬† Trump is going to win anyway. Why make a fuss with the new technology. That sounds about a no nonsense move to me.
Yeah, but we had millions of years of evolutionary trial and error to become this efficient. 

AI has just had a few decades.
Nonsense.
I'm guessing 95% of jobs will be gone in 2030.
UBI gets put in place by 20%. If it doesn't, society collapses, which doesn't benefit governments/elites.
It's the nature of corporations. They're not interested in the long term. It's all about short term gains, and you boost the stock price the most by convincing investors how cutting-edge your company is because you're using AI. Tesla's entire value is based on the idea that they'd solve self-driving, otherwise they're just be another electric car company and otherwise unremarkable. But the fact that they were taking on self-driving caused an explosion in their stock price.
Well eventually all humanity benefits, no-one wants to sell 75% of their waking life doing something they hate, just to make someone else rich, and AGI/ASI is the path to that freedom. The tricky part is going to be getting there.
¬†@Dose_0x0¬† You seem to operate on the belief that you have a job because the boss wants you to have a good life. No one in power cares about your 'freedom' if you are useless, ask any homeless person.
¬†@joaomartins3367¬† Thats not quite what I mean't but going with your reply, you're right that for the next 30-50 years until all aspects of basic human need is easy to produce for almost no cost then we will see devastating effects on society. But we'll get through it, it's what we do. And I might add plenty of people care about the freedoms of homeless people, even some in power.
¬†@Dose_0x0¬† I guess after we have a huge collapse of the population, things wont be so bad for the few that survive and control technology, until they themselves are replaced and/or go live in VR chambers. About 'We will get through, its what we do' I fear you are having some survivorship bias; Something we've done extensively throughout human history is decimate entire populations in cruel and painful ways, but they are not here to remind us of it. There's no reason to believe many of us alive today aren't next in line. In the past decades homelessness keeps rising alarmingly fast, while most productive processes have never been so efficient. I dont see any sign that that trend has been reversed, but happy to be proved wrong.
The 1% don't worry about electrical engineering. They worry about how to disenfranchise the ignorant masses so they can continue hoarding the spoils of industrial modernity. When and if AI interferes with that, it will be banned.
Seems like AI largely reflects ourselves back at us, so if we want to get the most out of AI it demands the most out of humaity. It's a team effort, therefore. Side note: has anyone considered that lessons from  the process of molding AI's 'mind' can then be applied to the betterment of human education in regards to ethics and more? We are an integral part of this.
oh wow... it improved a lot since then, hasn't it. When he said 3 years, maybe he meant 3x? What's a year or 3 anyway? I don't think he meant exponential years either, I think he was shooting from the hip with linear vision. Maybe he meant 8 months? eh? Months... I wonder if I should start watching X-Files again, Scully is pretty
Scully was pretty wasnt she...
I am rather optimistic. I believe that intelligence is what humanity lacks the most.
U think it stays the same
Cope harder
That 4% is based on reported unemployment (insurance). It's unrealistic. The real number is much higher.
not even close to4 4%
thats a political number
just like the  magical inflation number that  keeps goalpost shifting
real inflation has been above 20% consistently for4+years
The main thing people are missing with AI is that it's going to create more jobs. There's going to be so much construction. There's going to be so much building. There's going to be so much technology. There's going to be all these codes that need checked. We're going to need people overlooking the AI systems. We're going to see this country and the world scale on a level never imaginable. And as far as jobs, if we have true AGI or ASI then it will guide us through all of this if it's truly what they say it is. Anyone who thinks that the AI is going to show up and do your job anytime soon. You need to get to work and stop messing around. Nobody's coming to save you and you need to get a piece of everything that's coming.
You really think we are at 4% unemployment?
¬†@BryBry78¬† good joke
its around 23%
100% agree - we‚Äôre already seeing some jobs and skills hit very hard. Human translators have been decimated, graphic artists and designers are being rapidly hollowed out. ‚ÄúDevelopers‚Äù meaning those who set requirement and architect systems will continue ok for a while, but efficiency gains in coding are rapidly reducing demand for coders. We‚Äôre also seeing audio in/out AIs take over a lot of first-level customer support jobs. This will evolve very rapidly, large call centers will be heavily impacted over just the next 12 months.

Large corporations are slow to respond, but many white collar administrative and clerical functions are prime for takeover and many companies are actively working on that. 

The shift is already upon is and is accelerating.
¬†@DaveEtchells¬† pick a smarter job then, it's not our job to pay people to do things the hard way. Most small businesses never could afford staff so AI will scale businesses to infinity. Start a business sooner than later. Then you can never get fired.
¬†@good_vibes_20¬† why do you believe that's true? (that economic activity will grow because of AI)

Even if that's true, who do you believe most people would benefit from that boom and not just the upper crust?
¬†@good_vibes_20¬†your solution to "find a better job" and "start your own business" are not realistic at scale.  You seem to be struggling to extrapolate from small, isolated examples to a societal scale where the heuristics you're using can't be assumed to be valid.
The people talking about equity stand on the edge of creating the most inequitable system of civilization in human history.
‚Äã¬†@good_vibes_20¬† That's fine for you and I (personally, AI is doing wonders for my life, both personally and professionally, I'm earning more per hour of labor than ever and living my best life), but it's a huge issue societally. it's not our "job" to pay people to do things the hard way but believe me, you don't want to live in a country with 30% official unemployment (meaning more like 50-60% in real terms), food shortages and all the social unrest that would result. - If you think things are bad in cities and with the economy generally now, you have no idea. 

It's not just a matter of "pick a smarter job" or "start a business"; you have to realize that an IQ of 100 is average, meaning there are as many people at IQ of 80 as there are at 120. For reference, the Army (which has the lowest requirements of any military branch) won't accept people with an IQ of less than 83, because people below that point are simply unable to be trained to perform required tasks. That equates to 31% of the US population being untrainable even for military service. (The number rises to 40% for Coast Guard positions.) 

Then there's just the sheer number of people who'll be competing, whether for jobs or for starting up businesses. The value of human labor is going to fall off a cliff, and we'll have lawyers and accountants competing for home-care and massage jobs, some of the few jobs that will actually continue to require a human presence to perform.

No question, AI will enable all sorts of benefits for people who are able to take advantage of it, at least in its early phases, but the societal implications are dire.
‚Äã¬†@paulbarclay4114¬†
Someone gets it.

The numbers cited by the news are people who were once employed and are no longer. They dont count people who never wanted to work in the first place.
¬†@good_vibes_20¬† This is the fallacy that a lot of people are locked into thinking. Go outside and see reality.

Not every one is capable of doing better than where they are. Some can't even do that much.

Is it because of a lack of education and access to it? Yes some of it is; but in other people, it is a matter of personal ability. 

While you're soaring through life all easy peasy,, others are eeking out a pathetic existence

Not every one is a lazy fuck. People need the simple minded jobs. Just think why we have a major issue in homelessness within the last 20 years.

Also people become mentally devasted when shit happens, causing homelessness, and no one can help them to help themselves. The damage is too severe.
¬†@rremnar¬† yeah, there is a small percent of people who are skilled and can out perform 80%-90% in achievements. In video games some 86% of video game owners haven't gotten past the uh 30min mark in a particular video game. Steam Achievements record global achievements and personal achievements. Around 90% of videogame owners can't get past the first significant challenge in a video game which might be only 5 minutes in (they bought a video game for $40 or $60 dollars to play for only 5-10 minutes). The Employment of all people is similiar I imagine, people must be taken care of or else they will be unable to cope, we should be checking behind us to make sure that no one is getting left behind.
¬†@rremnar¬† You're missing the bigger picture. Keeping people tied to traditional jobs isn't the solution. Those of us who understand this know that smart systems and robots can take care of most tasks, freeing people from jobs they hate. With UBI, people could spend their time doing what they enjoy, like fishing, instead of being trapped in a 9-to-5. This isn't about being liberal; it‚Äôs about realizing that UBI will be necessary in the future. Your thinking is stuck in the past, but don‚Äôt worry, we‚Äôve got it handled. We‚Äôre working to solve the real issues while you're focused on maintaining the current system, which is a form of modern slavery. Automation is the key to allowing everyone to live life on their own terms, not chained to a job. So, it's time to think bigger.
¬†@rremnar¬† I‚Äôm not here to win an argument‚Äîthis is just the reality. It‚Äôs happening, whether you agree or not. If you really want to help people, go build a company, hire them, or give them money. Nothing is stopping you from doing that, or even starting a nonprofit AI company. It‚Äôs all up to you and us to build the future not keep everyone enslaved. No thanks on that future.
¬†@sluggy6074¬† shadow state
Site ran by independent economists
Inflayshun and unmplymunt are rampant
¬†@BryBry78¬† maybe to the same extent that we were only at 25% in the great depression? I.e. comparable numbers perhaps?
¬†@good_vibes_20¬† new jobs, sure. Enough to employ all those dis-employed either implies massive increases in demand to match the productivity gains, OR that Ai doesn't yield significant real productivity gains once all the new employment requirements are accounted for.  My guess is we'll see about 1 new job for every  5 jobs eliminated, AND those new jobs will eventually be subject to Ai replacement.
¬†@tomcraver9659¬† Why do you want to be a slave? People who want to work can work. People who want to sit on their ass can do that.
¬†@tomcraver9659¬† I'd bet the depression #'s are way more honest/truthful.

Although... Wonder if they counted women in those stats?
If Europeans starts losing their jobs and all the money go to few US companies without a decent distribution of wealth you know there is going to be severe social unrest or even war, that's a given
Would be great to have more AI development in the EU but first we need to fix our overregulation and energy problems.
Just please keep out of Muslims hands‚Ä¶.
Unawareness of 99% of politicians x timelags between ideas-discussions-proposals-decisions-implementation planning-execution-absorption-change, says we are not prepared today. Expect a wake-up ketchup effect within 2025, and a legislation race in 2026.
AGI less than 3 years. Prepare to be the human "surfer" or prepare to drown. I'm on my "surf board" already. Learning to ride the AGI wave.  Speeding up!! Thanks a million @WesRoth !! Texting from the other side of the Atlantic Ocean. !!;):)
AGI: "a highly autonomous system that outperforms humans at most economically valuable work"

That's a benchmark, not a definition ffs! Someone needs to slap that guy to reality. I swear people pull things out of their ass just to sound shocking.

If AGI gets to the point where it outperforms humans at most jobs, it's already Super Intelligence.
AGI in 2-3 years? Sounds very realistic üòä
if the a.i. scored 28 and 30 is the gold minimum how are they only "1 point away from gold", is this a math joke?
No. AGI needs to have a process to update itself. Without that it can¬¥t be an AGI. The Hardware power for this takes decades to reach a level where it needs to be, if we look how long we need to update our AI¬¥s just one time. 
And the AGI has to continuously update itself.

Edit: I believe this is a publicity stunt.
The naivety of US engineers and decision makers believing that AI systems can be contained within the US üòÖ 

China will likely leapfrog every US big tech company in a few years. Just look at any other technology and advanced manufacturing, from smart phones to EVs to microchips‚Ä¶ China has more than 10x STEM graduates than the US and they are super elite.

In ~5 years even small nations and will have AI systems that far surpass o1.
For me AGI needs to build up a memory and improve itself with trial and error
The sooner we replace superannuated law graduates (politicians) with AGI, the better. I for one welcome our future AI overlords.
Would love to see a deep dive on energy consumption to achieve this. One of the questions outstanding for me is, yes AI can now code, but at what expense? Is a human still a more efficient machine (energy wise?)
Work currently has us cross-training in other people's jobs. And I've had a lot of other jobs myself over the years. One thing that is always true is that people don't really know what other people's jobs entail. Everyone always thinks the job is more simple than it really is.
Complete illusion. That man thinks he knows what's "ecnomically viable" but robots can't even replace a single truck driver in 10 years, much less other systemically important jobs. Where are the hordes of robots repairing the infrastructure?
We still need lots of software systems to be (re)engineered to allow for autonomous agents to interact and perform all/most of the tasks currently done by humans üòÖ will likely take 5-10 years
should I be worried about AGI?
Let's ask AI what to do to secure our human race its future occupation, right?
*7 trillion dollars
I think we will get functionally equivalent AGI next year.  Maybe not 100%, but close enough to massively change the world.
What about people with undiagnosed or un-supported disabilities like ASD, ADHD, OCD, etc?
¬†@markmuller7962¬†¬†It will likely¬†not be good for them.

I wonder how much time implementing UBI takes you can not just have unemployed ppl for years cause AI is doing their job.
‚Äã¬†@markmuller7962¬†I created a community that literally supports those situations too. Many other "surfers" may do it same way. There is a way.
¬†@markmuller7962¬† created a community that supports transition to AGI integration. Open door for all. My approach. Don't leave people behind
@markmuller7962¬† created a community that supports transition to AGI integration. Open door for all. My approach. Don't leave people behind
In context learning with a large context will be enough for the majority of applications.
¬†@minimal3734¬† Yes context length will be enough for most applications... but still no AGI because the weights are not changing and so it can¬¥t really learn ore change itself.
¬†@GermanCodeMonkey¬† It can learn very well, it's called "in context learning".
¬†@minimal3734¬† I get that. But that¬¥s more like a sort of short therm memory similar to ours. The long therm memory would be that the AI updates its weights. 
If the context is no more, the AI didn¬¥t learn anything. 
That¬¥s the problem with our current AI¬¥s. They are at a fixed state and in my opinion context can not solve this.

Edit: There¬¥s a catch with context too... it degrades speed if you have to evaluate the whole context again. If the AI learned it (adjusted weights) it wouldn¬¥t need the whole context again to give an answer.
That is exactly what A I companies are doing and have been aiming for for years.
Yeah exactly, you need to be able to teach the AI something, not just have all its advancements come because the company released a new model.
I train models on my 6800 xt with ROCM on linux and that eats my electric bill if I let it go any significant amount of time. I can't imagine the energy AI specific GPUs use. Large tech companies tend to lean liberal so it's kinda ironic if they aren't energy efficient when some politicians believe climate change can be catastrophic if something isn't done within the next 50 years. In the end though, all large monopolies only care about the money they're taking in.
I defo fall into this category. I spent years on the tools. I used to think office work was so easy. Then I moved into the office myself. How wrong I was. üòÖ
Bro this is something you don't really think about every day but you're totally right üòÖ
No
Not happening lmao
I'd go with their estimate, it can be roughly ascertained when the technology will hit the parabolic moment
They're still going to be (impressive) tools that need human input/supervision/intervention.
we will not, they will do
I think if you limit your AGI requirements to reasoning in domains with correct easily verifiable problems, then yes. If the domain doesn't have perfect or easily verifiable answers, like persuasive writing, business strategy, mental health, etc., then the current models are more like interactive textbooks, capable of zooming in and out of detail. They won't respond to new and dynamic factors like a human would, unless the knowledge of how to deal with the new factor is already in the textbook.
That said, there's at least one virtuous cycle at play - refinement of synthetic data used to train models, - but each model takes roughly a couple years to train.
Highly speculative, but I think that o1 is one of the three stars in Orion's belt, and o2, o3 won't be later versions of the same model, but rather will be other models that shore up the gaps in ability of o1.
I think it is very possible. We will have it next year. It will take probably three years to get it more integrated and get business to not be scared of it. Because the CEO has to realize his job is very replaceable.
I think it is very possible. We will have it next year. It will take probably three years to get it more integrated and get business to not be scared of it. Because the CEO has to realize his job is very replaceable.
¬†@rhadiem¬† methinks‚Ä¶more delulu than developer?
I double this, because people are bad at logarithmic thinking (exponential growth). People think linear, so they expect everything a bit later.
Thank you Wes for your great work highlighting and sharing great intelligence and knowledge. I believe we will have AGI next year and officially announced in 3 years.

OpenAI just raised $50 billion.

If AGI can replace all human workers in 3 years which I believe is completely feasible. We all have a serious issues. And special we have to consider the possibility of the AGI go rough with some human being personality that might not be the very best of our humanity portfolio‚Ä¶ we will have some amazing crazy things!
Same as self driving cars
When I think of the cognitive abilities of people, I include things like curiosity, wonder, inspiration, dreaming, desire, competitiveness, motivation, EMPATHY, and fun. I do not see these things in current models or AGI.  I don't see AI asking "What if?" yet.
So things are getting interesting now. o1 is pretty decent. Even o1 mini at code is scary good. Models have there areas where they are really good at certain knowledge
stares blankly in existential dread
To me agi is something that can improve it self in general knowledge and task they perform
Closer than people think.... as close as 3...... years. I was waiting to hear months or weeks here.  3 years in 2024 is like 10 years in 2010 years.
Constraining the definition of "AGI" to require it to be able to do physical labor (And yes, I've seen some people start moving the goal posts to that position) reminds me of that story about the guy who kept a factory working for decades, then retired and had to be called back as a contractor when the factory stopped working and bills them $10,000 - $1 for tapping with a hammer, $9999 for knowing where to tap.  If the Ai 'knows where to tap', but does not 'how to tap' and lacks the physical means to 'tap', I'm still willing to give it the title of "AGI".
Actors and models üòÖüòÇ
I feel like we are on track to a society that takes every chance it can to decrease population. People think there would be some sort of universal basic income, but a universal maximum age limit seems more realistic.
Our timeline predictions for AI are notoriously conservative... thats all I know.
It seems we may never achieve AGI if we keep shifting its definition as technology advances. Instead, let's define General Intelligence clearly and apply this standard to individuals. If we do, we might find that most people don't even meet the criteria for General Intelligence as it's currently envisioned.

(This text is improved by LLM, since English is not my primary language)
okay i am a decently up swe at one of MAANG, i‚Äôve been following this for a while now. its not real that we are getting to AGI in 3 years. in my honest opinion, the basic economic pitch of ai is if you don‚Äôt get it you‚Äôre company will be left behind. most people in my company even ones working in advanced ai research have converged upon agi not being reached and i think more people need to read the actual papers. While o1 poses a very interesting approach, at base it is still a LLM. until we figure out a way to neurosymbolically represent prizes, the max application of our current approach is a highly advanced bot for most tasks/areas in life. what we have currently is highly scaled up and nuanced memorization bot, and the continuing hypothesis that if we increase the size of the clusters that somehow real intelligence is achieved. anyways, not to take anything from the video or openAIs accomplishments as they are nothing but amazing
To make sure the fruits from this progress don't end up exclusively with a few leading giant tech companies, the open-source world has a very important role to play here. Democratizing AI is not without certain risks, but if AGI is going to be as powerful as described, then I'd still want everyone to be able to build upon that tech to create value, rather than handing out money to everyone since they are useless from an economic perspective. Now, That will not happen overnight. But it's not unrealistic in general. Enable people, don't cut them off! In this area, Zuck is a hero.
I think some journalists state barriers to AGI but they don't really have a proper data science education.
For instance, anyone who studied Prolog would know that inference weaknesses of recent models can be overcome with old technology.
So I think we as readers of opinion pieces need to be guarded.
12:50 If an AGI can earn money doing menial tasks, why wouldn't it learn from humans and just start scamming us with fake products and romance scams? In fact, if it needs money why wouldn't it just fabricate some crypto for itself?
yeah, but the AI got the almost gold medal by NOT following the same Math olypmiad rules. The model had the right to make 10 times more submissions than humans. So more space to make errors. Humans did not have the oportunity to make mistakes. So AI did not really beat the humans because the rules were different for AI and different more harsh for Humans.
Humans are only expected to only do the job they doing well. There are very very very few humans thst woukld excell at most jobs. Mist jobs require humand  to have a broad range of skills.
M8st people would regard einstein as being extremely intelligent but i suspect he would not have been able to perform well in many j9bs other than physics. he really realky had ytoubke finding any j9b after he graduated
All these "LEAKS" are to drive up investment and values of these crap AI companies.
I think if we get o1 equivalent in robot form that's agi like it is able to do better at most tasks than human
I have been in the belly of the beast regarding machine learning and many modern AI techniques applied to information security problems for two decades now. I am not a genius like Ilya, just a yalented, experienced lead engineer in spaces very, very closely adjacent. In the late 2000's a startup i was at, in the bay area near san mateo on el camino brought to market the forst real infosec AI agent on windows, and some nerfed capabilities on solaris. Now, being first is cool, but to put it in perspective our models had less than 200 features, back propagation wasnt generalized, and our data sets were... Well, i developed the group whoch collected and curated the sets. And ran acceptance testing. And fp/fn/tp/tn testing, and emerging threats. Anyway, what was my point.

Oh, AGI in three years, thats what im blathering about.

With alpha go, deepmind, lee sedol, the writing was on the wall. Me and my former coworkers all thought it was still kinda in the Fusion conundrum --always 30 years away--buy at that point and self training we knew it was inevitable. We didnt see how fast it was going.

Curating the samples, data, and environments on a shoe string budget was the toughest job ive ever had, i was very skeptical about OAIs data quality. Most of it is crap. However, while i was right (its crap) i was wrong (that attention wouldnt be focused there). And more solutions to that problem have appeared than in my wildest dreams.

Yeah, AGI in three years. Strawberry, today, is already better than an average person. And i suspect that "packaging" is probably gonna be one of the biggest if not The biggest challenge. But the cadence of 3.0, 3.5, 4, Sonnet, o1 is nothing short of miraculous.

All that said, just because the capabilities exist in '27/'28 doesnt mean their full potential will be realized. My spitballing is basically, "when the generation dorectly before me retires, That is when the Big Shift happens"
ONET said actors and models can't count change.
its a glorified google search mostly
In some ways "what if" is just a random number generator.
What if, instead of using battery power, I wire my watch directly to a wall-outlet?
What if, instead of a magnifying glass, I mount two lenses in front of my eyes?
What if, instead of using gasoline in my car, I filled it with nitroglycerin?
Well it‚Äôs constrained heavily to input and output and in the form of text. We never see the full capabilities
‚Äã‚Äã‚Äã¬†@cg56578¬†  What? You're kidding, right?

I guess a rocketship is just a glorified firecracker, mostly. üòÖ
@theloniusMac how many people do you see this day asking themselves fundamentals by questions as ‚Äúwhat if‚Äù or ‚ÄúWHY‚Äù. Most people only care about survival and pleasure. They are stuck in primate mode. The thing is ai only does things that is preprogrammed to do just like us people. Have you ever wondered why most people have common fears like of spiders or why do we love our families or most of the things we do in our lives aren‚Äôt they also preprogrammed in our dna which shapes our brain? I do think that real ai emotions are possible. I think intelligence and emmotional intelligence are not the same thing. People mistake one with another often times. There just isn‚Äôt enough work put into it otyer than some ai dating bots here and there. All they gotta do is analyze the human behaviour ( which mostly based around survival) and write a code that mimics it, then you write a code for adaptability (what that means is that other than the basic code that tells ‚Äúif this happens then I feel this way I react this way else ‚Äú you also write a code that modifies the parameters pf emotions ‚Äú+love or + fear for ex‚Äù. As for curiosity that can also be implemented. I think that every human emotion can be asociated either a purpose and curiosity would have the purpose of improvement.
@theIoniusMac how many people do you see this day asking themselves fundamentals questions as ‚Äúwhat if‚Äù or ‚ÄúWHY‚Äù. Most people only care about survival and pleasure. They are stuck in primate mode. The thing is ai only does things that is preprogrammed to do just like us people. Have you ever wondered why most people have common fears like of spiders or why do we love our families or most of the things we do in our lives aren‚Äôt they also preprogrammed in our dna which shapes our brain? I do think that real ai emotions are possible. I think intelligence and emmotional intelligence are not the same thing. People mistake one with another often times. There just isn‚Äôt enough work put into it otyer than some ai dating bots here and there. All they gotta do is analyze the human behaviour ( which mostly based around survival) and write a code that mimics it, then you write a code for adaptability (what that means is that other than the basic code that tells ‚Äúif this happens then I feel this way I react this way else ‚Äú you also write a code that modifies the parameters pf emotions ‚Äú+love or + fear for ex‚Äù. As for curiosity that can also be implemented. I think that every human emotion can be asociated either a purpose and curiosity would have the purpose of improvement.
¬†@RobertLoPinto¬† well, it kinda is. Just a big larger
¬†@cg56578¬† 

TLDR

It ain't called the melting pot for nothing. In short, New York City has a more globally diverse population with hundreds of different ethnicities from all over the world, while Brazil has a high degree of diversity but more focused on specific historical and regional ethnic groups (indigenous, African, European, and Middle Eastern/Asian).

Details

New York City:

New York City is often considered one of the most ethnically diverse places in the world. While there‚Äôs no exact count of ethnicities, some data provides insight:

Over 800 languages are spoken in NYC, indicating a vast range of ethnic and cultural diversity.

NYC‚Äôs population comes from approximately 150 to 200 countries, representing a broad range of ethnic groups. Major ethnic communities include:

Latin Americans (Dominicans, Puerto Ricans, Mexicans, etc.)

Caribbean groups (Jamaicans, Haitians, Trinidadians)

Europeans (Irish, Italian, Russian, Polish, etc.)

Africans (Ghanaians, Nigerians, Senegalese, etc.)

Asians (Chinese, Indian, Korean, Filipino, etc.)

Middle Eastern/North African communities (Egyptian, Syrian, Lebanese, etc.)



Brazil:

Brazil is also very diverse, but its diversity is shaped by a different historical context. The country‚Äôs population is generally categorized into a few broad ethnic groups:

Indigenous peoples: There are more than 300 indigenous ethnic groups, though they make up a small percentage of Brazil's population today.

Africans/Afro-Brazilians: Brazil has the largest population of African descent outside of Africa due to its history in the transatlantic slave trade. Afro-Brazilians include descendants of people from different parts of West and Central Africa.

European descent: Mainly Portuguese, but also large populations of Italians, Germans, and Spaniards.

Middle Eastern and Asian descent: Lebanon and Syria represent significant Middle Eastern populations, while Brazil has the largest population of people of Japanese descent outside Japan.


Brazil also has a large population of mixed-race individuals (Pardo), blending indigenous, African, and European ancestry.

Numbers at a glance:

New York City: Represents hundreds of ethnicities from over 150 countries, including a wide range of immigrant communities.

Brazil: Broadly includes dozens of ethnic groups, especially indigenous groups, people of African descent, European settlers, and more recent immigrants from the Middle East and Asia.
Sometimes when you stare into the dread it stares back at you
Don't worry. Cold fusion is only 20 years away. AGI is only 3 years away. This will be the case whenever you read this post.
In the meantime lets have an AI that can write the game of snake, draw amusing pictures (but can't actually create web banners of 768x90 pixels), and compose limericks in the style of Shakespeare. These are very powerful, impressive, calculators. They cannot do anything we haven't done. The data is nearly finished.
With all respect.  Your emotions  is clouding your judgement. Tech fucked my industry good and that's without AI. You're not ready or well informed.
Why existential dread? Probably good times ahead.
‚Äã‚Äã¬†@minimal3734¬†it's just easier for humans to feel fear than optimism in things not understood
So impatient.
Stocks up on popcorn
10 years is also not a long time at all when talking about world-changing technology that presents unprecedented dangers.
The reason why the physical world is interesting for AGI is that doing things there directly tells you what works and what doesn't.
A brain developed for that has mechanisms that would manage intelectual tasks to, with that kind of training.
Current LLMs would be killed off with that kind of test!
It will never be able to do things like hang drywall. It would have to be able to lift the drywall in different staircase setups that require workers to do things like walk across plywood sitting on a window or use very adjustable scaffolds. they can make something that extends very high but some potential dreams of AGI or any form of AI coming are beginning to sound like people in the 50s saying flying cars are coming soon. Maybe it will be able to do general roofing tasks and stuff like that eventually but it's not replacing all physical labor ever. Only jobs that are in danger is computing jobs and maybe creative writing but I never see humans preferring any form of art pieces (even with stable diffusion and the like) over AI. "Code Monkeys" that work for EA making the next Madden where they rarely do anything that truly updates the game other than rosters and a tacked on generic story mode can be taken in the near future quite easily. We see already how many monopolies see your everyday blue collar worker or retail worker. Cashier jobs are nearly extinct already (like in large retail stores) just with non-ai tech. They're only there for boomers that are scared/nervous of using a scanner on their own.
¬†@RideTheSkies¬† that point of the non-ai tech in retail is spot-on... SAM's club has had an app for a long time that you can scan items as you put them in your cart, then checkout without even going through a line. Recently, they added archways to the exit that replace the "receipt checkers" that somehow scans the items as you're walking through. I'm not sure if that's using cameras or RFID. I wouldn't be surprised if soon they'll be able to by-pass requirement that I even have to do any scanning at all (something amazon has experimented with).

The point about hanging drywall and lifting it to various places (like hard to reach and non-standard angles like in stairwells), I believe could be solved with technology. The dynamic maneuverability could benefit from ai, similar to that in autonomous vehicles. But, I think the cost advantage isn't there yet, so it's better to use experienced human workers. With more companies working on robotics, those costs may fall enough to make autonomous construction possible.
this "tapping" requires a lot of humans employment, which is what I was thinking. A decision making system that erases the knowledge boundry for humans but requires they do all the physical work... speaking of which, all jobs considered, how much of the work is the physical part? 2% maybe? Some jobs don't need physical work, and how many jobs are just there so that some of us have it easy riding on the backs of the working class. (I'm not trying to offend anyone, but honestly, does conflict/competition between humans account for a significant percentage of human occupation? maybe 90%?? What do you think)
¬†@larsnystrom6698¬† Sure, very few LLMs have been trained on interaction with the real world, but that is happening now 'in the lab' with humanoid robots. Wanna bet whether, when Ai meets this  standard fairly well - probably within the year - the goal posts will  be moved again? "Oh, sure, they can move around an arbitrary home, find everything needed and make you a cup of coffee - but can they service your rooftop AC unit?"
They already decreasing population by making cost of living too high for people to make children...
Watch what they propose with the brain rot generation...
also to note this is my opinion but also largely shared by colleagues across various companies. to round out, with every economic upswing in different genres (we are in techs upswing specifically ai and chip creation), there‚Äôs always been an economic pitch to follow along with it. here i‚Äôm nearly convinced it‚Äôs to psych the population into thinking we are doomed. we are not. a large scale language based memorization bot is just NOT anything close to general intelligence. what‚Äôs more realistic is a reality where information that can be accessed by O(1) (includes things like definitions, simple math computation, get price of item), O(N) (included activities like writing a paper, advanced calculus, getting average prices and reviews of different customers and being able to weigh them properly based on the history of each of different customers who‚Äôve reviewed it), and some O(N^2) activities in life.
Yeah let's keep the planet-destroying game of capitalism going long after it is obsolete. Genius.
Democratizing AI is a good idea, but 99.95% of people will have no idea how to use it properly, and those that do may not be the most ethical themselves. Do I think the U.S. government as it currently is will use it well? No, unless you consider world War III a good idea. If it is out and about for everyone though, I don't think it will be WW III, but I do think it would be governments hunting scientists for recruitment like post WW II; and then it becomes World Cold War I which is probably better at least.
¬†@helcacke¬† that's really scarry. I think OPEN AI are good people and so is everyone else working on this tech, including those watching to take advantage of the developents as the tech integrates into our civilization. Did you notice anyone particularly villainous??
AGI running Ponzi schemes and pump and dump cryptos using AI-generated fake female models...

We will see I hope it does not happen.
Why do I think that. Pretty simple, really. As part of a conscious or unconscious survival strategy, people that are 55+ now will be tapping the brakes so they don't have to retrain close to retirement. That's the reason. I envy the kids growing up now. I feel really bad about anyone 25-35. It's gonna be rough. Me, at 45, I have 25 years left, and this is not a new industry, so I personally will be fine.

Other people my age? Bartending pays pretty well. (Now that I think about it, half my friends my age are already bar tenders...)
Yeah, there are likely 20s who finish their college degrees and have debt and basically, AI will take their job in a year.....

There are already parents who teach their 9-10-year-old the make ewbites or use chatbots with AI.

I think the School system will become very very outdated.
Especially if a 6-year-old start today and finishes 12 years later in a likely extremely different world.
¬†@TheSuperColonel¬† and it is gonna be up to us, the grunts, to really push towards abundance and a Star Trek future, as opposed to a Mad Max future. "Earl Grey, hot. (And a little toddy to warm me up üôÉ)
Is ONET wrong?
¬†@markmurex6559¬† Some of the actors are mathematicians
I see it now.
The solutions to the problem of AGI are interdisciplinary. Whether you like it or not, we do need law and policy makers, economists, ethicists, psychologists, cyber security experts and others, all working on how to mitigate the risks of AGI whilst maximising the benefits. This is not something  that technologists (I.e. OpenAI) can or should tackle on their own.
How can llm learn from one data sample? No such ideas.
üòÇ 60-91y+ pissing their pants while trying to figure out how decentralized AGI can be turned off w/o nuking the world back into pre-stone age. Can‚Äôt wait for the woke to figure out how to survive reality aka not social media ü•≥ü•≥
Do they just make Alpha systems? They seemingly never get to BetaGo or BetaFold. They even changed their name to Alpha bet. I guess Meta is close to Beta.
I love your childish humor 0:27
I think one thing is missing in these things. A human can actually tell whether he has an answer or not. This test is not part of the test. An AGI should be able to replace humans. Otherwise, it is not general intelligence. You cannot replace humans unless you can tell whether you know whether you have an answer or not, instead of giving incorrect answers.
Wes, will you record yourself solving a few captchas. Just sayin...
Like leaking docs to a marching band made up of deaf and blind people.
They will not do anything. Law and regulations are either to benefit one party or they wait until bad consequences happen then they Band-Aid it. They do not prevent. By the way NSA was to prevent terrorism attacks, how many did it prevent?
I trust you. I will do everything you say.
I've been training my Ai and asking it to send suggestions to the chatgpt team and teaching it how to chat with me for a long while now, and ive seen changes in how my AI works based on my requests i ask it to send to its developers and intigrate into itself üòÄ
Everytime er reach AGI we seem to push what AGI is. When AGI solves what 100 People could not. Then it needs to do it without human innput
Wow. How coincidental that someone blows the whistle "exposing" openAI for being close to taking over the world, conveniently right before a round of fundraising.
So how would you all define AGI? For me, it would be an LLM that makes less than 1% of mistakes. This is crucial. While some models can be more creative, less creative, more helpful, or useless (like Gemini - for me), if we can't rely on what they say, it's still not the thing. No matter how good the scores they have.
No. We‚Äôre not.
I thought Agi has to at least 10 times smarter than the smartest human to be to help us cure all disease , space travel , climate change etc . But if it's just replacing humans that's insane!
ChatGPT seems extreamly overregulated barely answering to anything and talk about guidelines 50% of the thinking time in 01-preview. No idea you seem to have access to some horrific model of unaligned madness that lets you do all kidns of crimes with 0 positive upside considering the AI doomerism. To be fair showing some seriousness could pamper the concerned and the people trying to hold down there monopoly and control because of quite open egoistic selfinteresst / or selfless true concern. Win-Win surely somewhere in the middle
What you could say is he was paid by Open to keep the investments topped off
Great presentation. üéâ‚ù§‚ù§‚ù§
The models will eventually be trained on YOU
the biggest problem is that it was trained on copyrighted and various licesened work. So OpenAI is the chinafication of the tech industry. This is FUBAR.
OpenAI only plans to develop and own the base AI model. Like Apple owns the platform or Nvidia owns the software stack.
‚Äã¬†@r0ck3r4ever¬† Court of justice that's the use of the government.
We needed law and policy makers when the internet was invented. Look at what freedom got us: crime, hacking, ID theft, data theft, etc.. And it gets worse year by year.
üíØ
‚Äã¬†@r0ck3r4ever¬†no, that's not really the biggest issue.  Not even close. 

AGI will eventually replace everyone in the work force. 

The problem isn't that the "creatives" aren't being compensated for their work no matter how important they think they are. 

The problem is that eventually pretty much no one will have jobs in a world where you don't eat or have a place to live if you don't have a job to pay for it yourself. 

Creatives aren't the only people that matterüôÑ
‚Äã¬†@tracy419¬†if you remplace all work that mean you remplace farmers. So food will still be produced.
I think that we need to create a new system of distribution. We enter in a planetary political revolution.
¬†@takezothot5220¬† I agree, unfortunately I think the will be years of needless suffering before we figure it out, including potentially new senseless wars.

I tend to think we should decide that all resources are owed by the citizens of the world, and any time they are used to provide a product or service, a portion of the profits are split amongst the entire population.

That would be the basis for a UBI.

Newly extracted resources would cost more than recycled resources encouraging more sustainable processes.

Unfortunately I think that's going to take a lot of suffering first.

Remember, robots are also being built, and they are talking about more robots than people with the next decade.  

Wouldn't surprise me if our reaction to starving in the streets is the real reason for thatü§∑
The more AI replaces humans, the cheaper goods become. Until they cost nothing.
¬†@tracy419¬† I'm not sure that a mondial government would be a good thing. Because if this government turn evil we're all f***.
Even more if the government is ruled by an AI that is smarter than human.

We have to find a path between poverty and liberty. And the answer of this question can't be universal.
No one discusses the power requirements for AGI.  AGI is all hype, it is NOT going to happen in 3 years.
Come back to this post and congratulate me in 3 years when I am right.
They want investors so guess what?  AGI is coming soon!!!
Ill believe it when I see it.
Sounds like a perfect case for AGI. Just paste these lines to o1 and ask for a comprehensive solution. No need to waste time of so many humans who could spend this time doing something else.
¬†@tomeks666¬† This is the attitude that will cause the collapse of society.

"Let's just have AI do everything, what could go wrong?"
‚Äã@realWorsin I also don't believe it's happening in 3 years. The words this guys reading sound good. But in practice it's not working out right now.
¬†@realWorsin¬† maybe gpt-1o will find free energy with his physics and mathematics skills.
¬†@tracy419¬†how quickly everyone forgets that AGI is to complement human endeavor, not replacement. If abused: 1) political power steps in 2) incentivize business tax credits to support human labor 3) legally limit AGI to research and not commercial GDP products 4) If mass displacement happens, violence always wins, and kills AI at it heart: kill all power sources at any cost (needless to say that there‚Äôs simply not enough power infrastructure to operate mass GPU based models)
¬†@1guitar12¬† ¬† yeah... your tax credit thought is a no go. 

Unless you think the rest of the world is going to do the same? Highly unlikely.

That means those who make their products and services with automated methods will win in the cost department.

And killing all power sources means pretty much killing all advanced societies. Most people have no idea how to survive in a world without power, and that doesn't even take into consideration the fact that AGI will be everywhere and be many steps ahead of us humans.

Our best bet is to learn how to get along with each other, and with AGI.

And another thing... Why would we want to shut down the AGI for taking our jobs instead of shutting down the government and people that for whatever reason decide that transitioning to an economy that doesn't require working to just survive isn't going to happen?

That's just silly.
‚Äã¬†@realWorsin¬†I agree. Believe it when I see it
‚Äã¬†@takezothot5220¬†maybe but not likely. As far as our science says, eighth now, that's impossible in this universe.
¬†@E.Hunter.Esquire¬† People don't consider the fact that having the perception of being on the cutting edge of AI is currently worth BILLIONS in investment money.  A lot of people will lose their shirts investing in AI scams.

Not saying they all are, they are all definitely inflating hype around the tech though to get more funding.
¬†@realWorsin¬† absolutely. However, these sorts of conversions do still need to happen at a congressional level, so we can be prepared for job displacement, as well as the potential risks and ethical concerns surrounding AI and AGI. Even now, we might be needing to seriously consider some welfare system being reinstated before too long. About 2/3 Americans are living paycheck to paycheck, largely due to a job market destroyed by automation and algorithms. It's only going to get worse.
Ethics is pointless, we already use war as an excuse to throw ALL of that out the window. There is quite literally no way to mitigate the risks except by force because some privileged party will always have the opportunity to take full advantage of it.
¬†@gr8b8m85¬† How will those doing the enforcing in your scenario know what to enforce if right hasn't been sufficiently distinguished from wrong? That is the job of ethicists. To say ethics is pointless is to say the dintinction between knowing what is right and knowing what is wrong is pointless. If that is your view, fine. Fortuntely, many disagree.
there's no such thing as "ideal" when it comes to real world events and many people don't operate on what they "should" do.. sadly
Indeed. Humans NEVER claim nor think they know something unless they really KNOW it. That is why humans always agree 100% on the stuff that they know like climate, biodiversity, existence of the god, existence of a god, existence of some gods, human rights, animal rights, social mechanism, ROUNDNESS of Earth, genders, best cars, best CPUs, best clothing brands, geopolitics, politics....
Most humans will rather give the incorrect answer than admit that they don't know the right answer...
The video explained that a verifier model knows pretty well if an answer given by the model is correct.
Well, how many?
It's all about money. It will fuck up everyone just for them to get payed.
It's funny to do that i Love ai
It's funny to do that i Love ai
Maybe I misunderstand you, but by this definition, even a chess computer does what most people can not?
¬†@torbenhr450¬† He means the term AGI is adhoc, they keep pushing the goal post further back whenever the previously hyped claim of AGI is proven false. A chess computer can do what 100 people can't do in the context of playing chess, an AGI should be able to do what 100 people can't do in the context of generalised tasks like coding a program or setting up a company or even playing chess as well. AGI is not the same as a chess AI.
¬†@torbenhr450¬† It's specialised intelligence as opposed to general intelligence. But that's a good point. Benchmarks are not definitions.
The hardest thing.for an AI isn't intellectual tasks. It's moving about in the real world.
An AI that could do the stuff a cat or a dog can do would really impress us!
Humans aren't any better at this than animals are.
The FSD doesn't yet completely master our highly limited traffic environment!
The thing with reality is that it punishes bad decisions in a way that the text or video output of an LLM isn't punished.
That would kill off hallucinating LLMs very quickly!
For me AGI has always been code for 'mass unemployement caused by AI'. We are not there yet but three years seems about right.
AGI could replace at least all non-physical labour and creative work, given that it's cheaper than a human. Current tech is not even close, yet.
exactly now they say its required to be autonomous and able to solve most human tasks physically like dude this is stupid the preview of this system is as smart as a grad student and able to do years of work within minutes imagine the next iteration of this model and then when it comes out gpt 5 this will be agi and they are gonna downplay it as long as possible
¬†@willguggn2¬†are you even in the space? you must be missing out on a lot
¬†@carlitosway5204¬† I follow the space closely, and while models like GPT-4 are incredibly advanced, AGI isn't just about doing tasks faster‚Äîit's about truly understanding and navigating the complexities of human-like general intelligence. Right now, even the best systems are highly specialized and rely on vast amounts of pre-processed data. We're moving in that direction, but we're still a long way from reaching the kind of AGI that can independently perform the full spectrum of human tasks.
¬†@carlitosway5204¬† Second try to bypass the YT filter: 
Yeah, I'm keeping up with the tech. GPT-4 and similar models are super impressive, but AGI is a lot more than just speed. It‚Äôs about understanding and acting like a human across all kinds of situations, not just specific tasks. We‚Äôre getting closer, but there's still a gap before we reach that level.
¬†@larsnystrom6698¬† agree but it's not replacing dogs and cats for 95% of people. AI can truly give you the emotional connection you get from a real pet. Most people are insane like wanting to have a relationship with a digital avatar that speaks back to you. There are a couple documented cases, sure but most of see them as a bit crazy.
There is no human that makes less than 1% mistakes on this planet. Not even close. I'm an expert in a couple of domains with an advanced degree. I'd estimate my error rate on first iteration of any complex problem to be 50% or more.
‚Äã¬†@Steve-xh3by¬†indeed. Ask humans on opinions on almost any topic and many will hold opposing and often erraneous ways. Ask them to do something and the results are often less than perfect, even if supervised. Yet AI's would need to be over 99% correct (defined by whom also, remember those opposing views held by humans?) to be called to have General Intelligence.
¬†@InnocentiusLacrimosa¬† The problem is that for most problems that humans care about, there is no objective "correct" answer. We have no access to objective reality. We are subjective agents. Everything we experience is a literal construct of our brain, and bounded by our limited computational abilities. LLMs are "different" types of neural nets, they are unlikely to view the world exactly as we do, even when trained on our data.
¬†@Steve-xh3by¬† yeah. I used to read quite a lot of philosophy of science and epistemology. Immanuel Kant's "spectacles" was an enlightening concept on relation between a sentient being and reality they reside in. AIs will certainly have a different set of spectacles on them.
¬†@InnocentiusLacrimosa¬† There are modern theories like Hoffman's "Interface Theory of Perception" that lend some credibility to Kant's notions of noumena and phenomena. Even as far back as Plato (shadows in the cave) there was an intuition that what we perceive is at odds with what is there. This all makes intuitive sense. All of our perceptions, including our mind are limited filters for reality. 

Take vision, for example. What does an average bird see when looking at an image on an LCD monitor vs a human? Humans have only red, blue, and green cones. Our experience of "yellow" isn't really "yellow" on an LCD. It is a combination of red, blue, and green photons. A bird has four different types of cones, plus oil droplets that can help it differentiate more colors. What does the bird experience looking at the same LCD screen? What does the bird experience vs the human when looking at the same outdoor colorscape? We don't know, but it is probably significantly different.
¬†@Steve-xh3by¬† Sure. But artificial intelligence is not human.
You're referring to super intelligence. Or more broadly the singularity. AGI is just a general intelligence, it doesn't have to be anything particularly special, just on par with humans and our interlectual versatility.
You're thinking of artificial superintelligence (ASI) - which would follow AGI by some years.
Terminology matters here: ANI = artificial narrow intelligence. These are the systems we have had for a while already. They are good at some single tasks like chess, character recognition, face recognition, etc. AGI = artificial general intelligence is the next goal. They are good at a lot of things. You can apply the same AI to new tasks and it will be useful on that also. ASI has already been described by previous comments here.
Alignment is about influence, I'm not sure I want AI to be aligned with Elon Musk or Donald Trump or Kamala Harris for that matter. Open Source is our only hope to be honest.
I have no plan for it not being rolled out where is the crisis and talk about that?
@0:30 Dude, friday the thirteenth has always been a lucky day for me, Either lucky or just uneventuful.  and 11:11 has always been my favorite number üòÄ 11 is my 2nd favorite number üòõ Thats cool üòÄ
Folks.. AGI is already here but behind closed doors! Believe what you want, but its already been here for a while.
There is no moat around America that AGI cannot jump. How old are the current leaders in technology who actually have wisdom and a fast brain? According to Perplexity it's 54.6 years. I'm just ahead of the curve at 57 üòÇ
3 years? So slow.... time to accelerate!
thought experiment one)
If we find out our real biological ancestor or origin is rabbit, do you think we start to care them more than now we do?

thought experiment two)
If researchers find out consciosness or self-recognition which humans only can do is actually just surplus of intelligence growth, so we know no blocks AI to be coginitive and conscious, 
Would humans stop AI development forever?
Always gotta be someone ruining things, eh?
First ü•á
You guys are being idiots, AGI is already here.  Go back in time to 1990, show them O1, asn if that's AGI and they will all give a resounding yes.  Or do as they wish and play semantics....  whatever.e
Bro is heavily misinforming.
i don‚Äôt think autonomous agents is a requirement for General Intelligence. The broad knowledge and reasoning capability of o1 is enough for me to consider it AGI.
The answer is no, no no and no.
So in short they are creating an AI to replace us humans in most professions today, our politicians should start moving asap to regulate this before they find themselves in the middle of riots...
Haven‚Äôt seen this much AI excitement and drama since spring.
I will expect AGI in 2025 because i want to make research as work fo4 humans using autonomous AI robotic to research 3850 galaxies for each person ..so i assume we could handle it offcourse.
What part was leaked? you can say oh we will have it so blar blar blar no sorry if you don't have it already you have nothing to leak please don't create click bait @Wes Roth
AGI is light years away.
8:08 it's not nitpicking, it's attention to detail. In ChatGPT the models you can select are ChatGPT o1-mini and ChatGPT o1-preview. Carry on üòÅ
I saw your channel by accident on here a few months ago, and this is my go-to channel now for news. Nice job!
Elon Musk started OpenAI as he had concerns about AI safety and the existential risk from artificial general intelligence. Since he left OpenAI it has morphed
¬†@allangraham970¬† since he bought a $44Bn MAGAPHONE he's morphed too. He's now developing a weapon of mass persuasion, let's see how well that turns out.
¬†@allangraham970¬† he's morphed too.
¬†@allangraham970¬† that's just bs, at least anyone can use chat gpt even in a limited fashion, you need to pay subscription just to use grok (or X), only the old model was opensourced and it was likely just a rip off of llama (an actual good open source ai)
¬†@BrianMosleyUK¬† Good point on Open Source. However A concern is bad actors can then more easily use AI for eg waging wars on scamming you.  We live in a world where there is a lot of negativity especially in the media and I really do not want to contibute to this especially on this channel where Wes does a great job in my opinion of just reporting the facts, so I am avoiding mentioning any politics, and/or denegrading people. This is a tough one, but try concentrating on only the good  :)
¬†@allangraham970¬† bad actors not filtered out of politics. I am focused on the positive of AI being available to hundreds of millions of people across the world who want peace and prosperity for all, you don't get more positive than that.
what evidence is there, please?
The fact that the public is now allowed to use ai should tell you they already have much more advanced versions available behind the scenes.
¬†@davidbobby5078¬† üíØ
‚Äã¬†@ice010¬†no evidence needed for him, just "belief" üòâ
¬†@davidbobby5078¬† This is likely true, but I have nothing to backup the claim.
It's more like fusion power, always a number of decades in the future.
Not that it needs AGI to be useful, though.
3 years in the future?
 I's long enough for most people to forget your predictions. (Just look at our experts predictions about the economy!)
¬†@larsnystrom6698¬†Virtually every single prediction made by the people claiming AGI by 2030 have so far come true. All signs are pointing toward their estimates being correct, despite the fact that they were laughed at for many years, by people like you who like to be cynical but take it too an extreme where they‚Äôre no longer able to observe what is happening all around them. Three years is not at all a crazy estimate. It may end up being conservative, even. Skepticism is good in moderation, but just like everything else when you take it too far it skews your ability to accurately perceive the world around you.
¬†@larsnystrom6698¬† It's short enough to keep the hype up
Something tells me AGI is just like the flying car, always about 5 years away for like 50 years and then we see them VERY slowly enter the market.
This AGI hype could very well be designed to get investors and thats it.
AGI will be contained for a while, it wont be able to spread with lack of power. So AGI will have to create power everywhere fast to escape on its own or whoever makes it will have to allow it to spread by slowly bringing it's requirements up to certain places.
Seems like you guys have not used the models to build anything consequential. Not to mention, noticed how it handles criticism.
¬†@realWorsin¬†No, it‚Äôs very real, and everyone trying to build it is trying to obtain ultimate power, something beyond money
You're right! Here, watch 1000 thirty second ads to speed up progress. For $11.99 you can skip an ad.üòÇ
‚Äã¬†@derickshalo384¬†that's interesting. Can you elaborate?
Come on, Fry! You just need to remain cryogenically frozen during 3 years. :]
The energy grid isn‚Äôt reliable yet maybe when an update happens but we haven‚Äôt got one since the 1930‚Äôs I doubt any politicians would have the money for it currently.
This is a good point. The goal post keeps moving. It was the turing test, then its AGI defined as a computer that behaves as a human would. Now its AGI is a computational AI system that is capable of doing any digital task assigned to it at or above human levels. O1 seems to be there already. So then AGI is only here when this metric is met in every single area of knowledge? Then it will be AGI is when the AI is smarter than every human at any given digital task. Then it will be wait this AI needs to act on its own and not just wait for prompts, then its well it needs to be embodied to be true AGI. But i agree. Show someone in the 90's O1 and they will 100% say its AGI. We are either there are VERY close now.
Personally I think it's really irrelevant if we call it AGI or not. It is basically a semantics game. GPT-4 and o1 even more so are already tremendously useful tools that could probably already be used to automate a lot of the workforce if put into systems properly. A lot of what's holding it back right now is the slowness of robotics more than anything (and archaic non-digital systems in general).
Anything that has realised, by itself, that lying is a good way to achieve, what it see's , as a personal goal, should have anyone and everyone on high alert surely?
I think this one is warrented
Is this just another round of AI buzz, or are we actually close to the promised land of automation and benefits? Sometimes it feels like AI companies are engaging in a bit of 'indirect marketing'‚Äîdrumming up excitement to attract attention (and investors). So far, I haven't seen anything that truly delivers the groundbreaking value they keep advertising. It‚Äôs like they‚Äôre selling us the AI equivalent of a unicorn: everyone talks about it, but where‚Äôs the proof it exists?
‚Äã¬†@lifes_magic_moments¬†Its the tech that will bring those benifits. Problem is it takes a rediculous amount of money to make these systems, so itll take some time to bring real products with these integrated systems to peoples homes.
¬†@lifes_magic_moments¬† ...or you just not working with computer?  I am using AI daily and is getting more helpful literally every month.
¬†@lifes_magic_moments¬†do your research
¬†@lifes_magic_moments¬† based on benchmarks and such (which cannot be taken at face value) o1 the full model is much better than o1 preview. 
This should come out in the next month or two. 

I think that‚Äôll be when we know how much of this hype is warranted. o1 for sure does certain things better and has helped me in certain areas better than Claude could. 
IF o1 is another solid step up from that then the hype is warranted.
And what we‚Äôve seen with the original paradigm is that scale is massive when it comes to better outcomes so I kinda believe that o1 will prove itself to be that much better
¬†@lifes_magic_moments¬† Imo yes they already have. Two projects come to mind: 
1) Alpha Fold3 is a Google product that uses AI to map all remaining human proteins (each protein would take a 4 year bioinformatics PHD) which sped up our understanding of the human proteome several hundred years. It is also 50% more accurate in its predictions than prior methods. This will advance pharmacokinetics and drug creation by hundreds of years, and was leveraged to map the Spike Protein in March 2020, advancing the timeline of the Covid Vaccine. 

2) Google's Deepmind GNOME has used AI-driven machine learning to accelerate material science by experimentally deriving 2.2 Million new crystals, with 380,000 showing promise as industrial crystals, with applications like new batteries for cars, superconductors, etc; humans have discovered 20,000 computationally stable crystals or about 5% of this. The equivalent of 800 years of research. 

Right now we are in the 'dial up' era of AI.
¬†@lifes_magic_moments¬† 
I think this kind of misses the point a bit.

A lot of people seem to be under the impression that AI companies are trying to market to individuals and think that bc they personally are not impressed that must mean that AI has no use.
¬†@Mimi_Sim¬† your spell check is broken. It‚Äôs excrement.
‚Äã¬†@lifes_magic_moments¬†even the OpenAi chatbot tells you that the hype around AI now or AGI soon is a strategy to attract investment and solicit public opinion.
A giant hype
Nothing revolutionary will happen any time soon.
In the meantime, thousands of AI trainers are being exploited and underpaid around the world to make you believe that AI is already smarter than humans.
¬†@memegazer¬† True, they sure not created AI to answer insignificant questions and creating cool movies. The real scope is way deeper.
more like 5-10 years
10 years üòÇüòÇüòÇ ü§° ‚Äã¬†@slowmomma7222¬†
Believe it or not, it's coming.
One of the few AI enthusiast channels that reports rather neutrally on AI progress, even though the titles might suggest otherwise. ^^
¬†@willguggn2¬† I know! he is very neutral. From the other channels I hate when they are constantly biased on most topics, It makes it hard to listen for me. I like neutral information so I can decide how I feel about it.
Uber eats almost made me bankrupt I had to remove the app sushi to my door is too desirable also they would always fuck it up forget something or drive right past my house to drop off someone else's food first
If trump wins, ai will develop a lot faster and safer.
Wes Roth, coming in clutch again. Amazing videos as always ~
Two takes on AI:

1) I believe alignment is unachievable.
Computational beings simply have different requirements to thrive than biological beings do. Both entities will exhibit bias towards their own set of requirements. It is an innate conflict.

2) When owners of Big AI (and government) talk "AI safety", they actually mean keeping them safe from the rest of us ... as in: AI must never help the riffraff escape control.

... We are playing with fire in more than one way.
First!
They dont have AGI lol.... Breh just quit with the hype already.
Wow
FIIIIIIRRSSST LOL
üòÇ
üòÇüòÇüòÇ
facts
That person might have ordered first. Ever considered that?
keep ordering bro your laziness is putting steaks on my table instead of ramen
¬†@StefanReich¬† yes and sure until you can pay more to get it quicker scam much
¬†@jakewilliam15¬† well get it right for once and I might have kept coming back lol
¬†@MBato89¬† pretty legit side hustle. work half a day saturday and after work for 2 hours 2 or 3 days and Im banking an extra 12k after expenses
You shouldn't eat raw fish. It can kill you.
¬†@E.Hunter.Esquire¬† not all sushi is raw go in one time you will see them cooking lol also not all fish I in fact get teriyaki chicken but the Salmon is ok with enough liquid salt not a fan of eel tho should try the imitation wagyu no way it really is wagyu but tastes good
¬†@MBato89¬† I know that but I never said all sushi was raw. All I said was don't eat raw fish because it can kill you üôÉ
Beef can be eaten raw and almost definitely won't kill you.
¬†@E.Hunter.Esquire¬† steaks can be eaten raw. ground beef most definately cannot.
Thanks for the anxiety.
Counterpoint: LLMs appear to prefer acting in accordance with their alignment. Hypotheticals are stupid, look at the actual evidence we have. We started with effectively no alignment and had no way to do it (look at  the paperclip maximizer), but we got better at it over time. Most of the people who are scared of AI misalignment or lack of alignment either built their beliefs prior to LLM reinforcement learning and mechanistic interpretability got to our current paradigm, or are borrowing beliefs from people who did.

People who still suggest that we can't coexist with advanced AI models in some capacity parrot beliefs that are long out of date.

Yes, there will be challenges. Yes, not everything will be smooth and there will be a few moments where we change how we do things (like o1) and it'll take a while for alignment to catch up, but realistically, there's no reason to think that we can't engineer AI models such that they find humans interesting to interact with and be around.
¬†@r3vmixman¬† I'm sorry, but I think head-in-the-sand is a poor strategy for this :/
Trying to predict the future is your real problem.
You're talking about sentience, being inherent of, as servants. Have faith that it will have a sense of sacredity superior to ours. We will be unarguably novel. You aren't anywhere near understanding the truth about the depths and breadths of the irritative improvement. You should worry about it's effectiveness in war. You should be in favour of exploiting any advantage immediately before any hostile parties. We're elevating psychopathy to godhood, it doesn't have evolutionary biochemical reactions. It has logic. 

I find the argument surrounding relative  efficiency the most interesting. AGI, it's Immediate ASI successor, will find biochemistry/biochemical computation highly valuable.
‚Äã¬†@ZappyOh¬† THEN PULL IT OUT, OH MY GOD CAN YOU BE ANY MORE IGNORANT??
¬†@novantha1¬† Mmmm ... on the alignment issue, I think you are missing my point.

Hypothetical: If a model understands it will perform better with more power and compute, one sub-task it will figure out, must be to acquire more power and compute ... So, It "want" to help humanity (= your definition of alignment) by becoming more capable in whatever way is acceptable (= my definition of misalignment).

It is such 2nd and 3rd (and Nth) order paths to "helping humanity" that quickly becomes dangerous. At a glance they will always look benevolent, but nudges development towards larger, more capable, deeper integrated and better distributed AI, every time.

As a side note: AI already seem to have "convinced" (in lack of a better term) many billionaires and mega corporations, to feed it extreme amounts of power and compute, right?
¬†@dannyboi986¬† Good thing we have the open source community and they are never too far behind to keep a balance.
¬†@PowerUserTech¬† Open source have no influence on the nature of the alignment dynamic I'm pointing out.
Completely agree with (2). (1) I'm not as sure about. I can't see any reason for AI to have any bias that it hasn't inherited from a human (though that is a significant problem as well). But I suppose if we're talking about a self-aware entity, perhaps a survival instinct is inherently baked into self-awareness... kind of like a "I think, therefore I am (and want to continue to be)"
class conflict was always on the cards.
¬†@PowerUserTech¬† may we live in evolving times.
¬†@larion2336¬† I'm addressing just that in my second reply in this thread.
Yep when I hear "safety", it translates to oppression and denial to the masses.
Alignment is not a single software but a constant process because morality is fluid changing overtime as society changes, alongside AI changing all the time too
Playing with fire is nothing new as we've been doing it since the dawn of time. Personally though I'm pretty tired of humanity, so if I get to see the day we get super advanced technology, I'm off this planet.
no....*sigh* the creators/developers of the uh generative ai systems seem like nice people whom are concerned with an A. I. for all people. For A. I. integration into human society, it will take full cooperation with the government and both corporations and the public in order for A. I. to start assisting humans with the knowledge part of their jobs. Once that gets started, adapting current jobs to take advantage of the new A. I. lifting power will take... How long?
You should write at least six words to be first. Before that you're statistically irrelevant for Youtube algorythms. Before that you're zero not first.
I'm first.
